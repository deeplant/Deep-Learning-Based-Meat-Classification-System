{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c6121f60",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1604\n",
      "등심1++_000471.jpg\n",
      "Filtered valid image paths for 20240904: 97 / 107\n",
      "Filtered valid image paths for 20240905: 101 / 101\n",
      "Filtered valid image paths for 20240906: 69 / 70\n",
      "Filtered valid image paths for 20240910: 11 / 110\n",
      "Filtered valid image paths for 20240912: 107 / 107\n",
      "Filtered valid image paths for 20240924: 119 / 120\n",
      "Filtered valid image paths for 20240926: 78 / 80\n",
      "Filtered valid image paths for 20240927: 90 / 91\n",
      "Filtered valid image paths for 20241008: 113 / 113\n",
      "Filtered valid image paths for 20241011: 60 / 60\n",
      "Filtered valid image paths for 20241015: 65 / 65\n",
      "Filtered valid image paths for 20241016: 65 / 65\n",
      "Filtered valid image paths for 20241017: 67 / 67\n",
      "Filtered valid image paths for 20241018: 44 / 44\n",
      "Filtered valid image paths for 20241022: 88 / 88\n",
      "Filtered valid image paths for 20241023: 47 / 47\n",
      "Filtered valid image paths for 20241024: 47 / 47\n",
      "Filtered valid image paths for 20241029: 111 / 111\n",
      "Filtered valid image paths for 20241030: 43 / 44\n",
      "Filtered valid image paths for 20241031: 16 / 16\n",
      "Filtered valid image paths for 20241101: 15 / 15\n",
      "Filtered valid image paths for 20241105: 92 / 93\n",
      "Filtered valid image paths for 20241106: 64 / 64\n",
      "Filtered valid image paths for 20241107: 45 / 45\n",
      "Filtered valid image paths for 20241108: 15 / 15\n",
      "Filtered valid image paths for 20241112: 102 / 102\n",
      "Data saved to ../dataset/meat_dataset/only_new_1112.csv\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import pandas as pd\n",
    "import ast\n",
    "import re\n",
    "\n",
    "def find_header_row(file_path):\n",
    "    required_columns = ['No', 'SEX', 'SEX(암,거세)', '등급', 'GRADE']\n",
    "    \n",
    "    # 엑셀 파일을 열고 각 행을 확인\n",
    "    for i in range(20):\n",
    "        df = pd.read_excel(file_path, header=i, nrows=1)\n",
    "        if all(any(col in df.columns for col in required_columns) for col in ['No', 'SEX']):\n",
    "            return i\n",
    "    \n",
    "    raise ValueError(f\"Required columns not found in the first 20 rows of {file_path}\")\n",
    "\n",
    "# 제외할 이미지 목록 읽기 함수\n",
    "def read_exclude_list(file_path):\n",
    "    exclude_images = set()\n",
    "    if os.path.exists(file_path):\n",
    "        with open(file_path, 'r') as f:\n",
    "            for line in f:\n",
    "                try:\n",
    "                    # 문자열을 리스트로 변환\n",
    "                    image_list = ast.literal_eval(line.strip())\n",
    "                    # 리스트의 각 이미지를 set에 추가\n",
    "                    exclude_images.update(image_list)\n",
    "                except (ValueError, SyntaxError):\n",
    "                    # 라인을 파싱할 수 없는 경우 무시\n",
    "                    continue\n",
    "    return exclude_images\n",
    "\n",
    "def get_image_paths(image_directory):\n",
    "    image_paths = []\n",
    "    for root, _, files in os.walk(image_directory):\n",
    "        for file in files:\n",
    "            if re.match(r'[\\w\\+]+_\\d+\\.jpg', file, re.IGNORECASE) or re.match(r'\\d+_\\(\\d+\\)\\.jpg', file, re.IGNORECASE):\n",
    "                image_paths.append(os.path.join(root, file))\n",
    "    return image_paths\n",
    "\n",
    "def extract_image_number(file_name):\n",
    "    match = re.search(r'_(\\d+)\\.jpg', file_name, re.IGNORECASE) or re.search(r'_(\\(\\d+\\))\\.jpg', file_name, re.IGNORECASE)\n",
    "    if match:\n",
    "        return int(match.group(1).strip('()'))\n",
    "    return None\n",
    "\n",
    "def process_data(base_directory, image_directories, excel_files, output_file):\n",
    "    exclude_file_path1 = '차이_4이상.txt'\n",
    "    exclude_file_path2 = 'nan_값_포함.txt'\n",
    "    exclude_images = read_exclude_list(exclude_file_path1).union(read_exclude_list(exclude_file_path2))\n",
    "    \n",
    "    print(len(exclude_images))\n",
    "    if exclude_images:\n",
    "        print(next(iter(exclude_images)))\n",
    "\n",
    "    dataframes = []\n",
    "    current_number = 1  # 시작 번호\n",
    "\n",
    "    for folder_name, file_path in excel_files.items():\n",
    "        try:\n",
    "            header_row = find_header_row(file_path)\n",
    "            df = pd.read_excel(file_path, header=header_row)\n",
    "            \n",
    "            # 컬럼 이름 변환\n",
    "            df.columns = df.columns.str.strip()\n",
    "            \n",
    "            # 'No' 컬럼이 존재하지 않으면 KeyError 방지\n",
    "            if 'No' not in df.columns or not any(col in df.columns for col in ['SEX', 'SEX(암,거세)']) or not any(col in df.columns for col in ['등급', 'GRADE']):\n",
    "                raise ValueError(f\"Required columns 'No' or 'SEX' not found in {file_path}\")\n",
    "            \n",
    "            df = df.dropna(subset=['No', 'SEX' if 'SEX' in df.columns else 'SEX(암,거세)', '등급' if '등급' in df.columns else 'GRADE'])\n",
    "            \n",
    "            # 'No' 열에서 숫자만 추출하여 사용\n",
    "            df['Original_No'] = df['No'].apply(lambda x: int(''.join(filter(str.isdigit, str(x)))) if pd.notna(x) else None)\n",
    "            \n",
    "            # 이미지 경로 가져오기\n",
    "            image_paths = get_image_paths(image_directories[folder_name])\n",
    "            image_dict = {extract_image_number(os.path.basename(path)): path for path in image_paths if extract_image_number(os.path.basename(path)) is not None}\n",
    "\n",
    "            # 데이터프레임에 이미지 경로 매칭\n",
    "            df['SEX'] = df['SEX'] if 'SEX' in df.columns else df['SEX(암,거세)']\n",
    "            df['SEX'] = df['SEX'].replace({'거세': '거'})\n",
    "            df['SEX'] = df['SEX'].replace({'거세 ': '거'})\n",
    "            df['grade'] = df['등급'] if '등급' in df.columns else df['GRADE']\n",
    "            df['image_path'] = df['Original_No'].apply(lambda x: image_dict.get(x, None))\n",
    "            \n",
    "            # 존재하는 이미지 파일만 필터링하고 제외 목록에 없는 이미지만 선택\n",
    "            df = df[df['image_path'].notna()]\n",
    "            df = df[df['image_path'].apply(lambda x: os.path.basename(x) not in exclude_images)]\n",
    "            \n",
    "            # 새로운 연속적인 번호 부여\n",
    "            df['No'] = range(current_number, current_number + len(df))\n",
    "            current_number += len(df)  # 다음 폴더를 위해 번호 업데이트\n",
    "            \n",
    "            # 유효한 파일 경로가 몇 개인지 로그 출력\n",
    "            if not df.empty:\n",
    "                print(f\"Filtered valid image paths for {folder_name}: {len(df)} / {df['Original_No'].max()}\")\n",
    "            else:\n",
    "                print(f\"No valid image paths for {folder_name}\")\n",
    "            \n",
    "            # 필요한 열만 선택 (No, grade, SEX, image_path)\n",
    "            df['grade'] = folder_name  # 폴더 이름을 grade로 사용\n",
    "            df = df[['No', 'grade', 'SEX', 'image_path']]\n",
    "\n",
    "            dataframes.append(df)\n",
    "\n",
    "        except ValueError as e:\n",
    "            print(f\"Error processing {file_path}: {str(e)}\")\n",
    "            continue\n",
    "\n",
    "    # 모든 데이터프레임 병합\n",
    "    if dataframes:\n",
    "        all_data = pd.concat(dataframes, ignore_index=True)\n",
    "        all_data.columns = all_data.columns.str.replace(r'\\(.*\\)', '', regex=True).str.strip()\n",
    "        all_data.columns = all_data.columns.str.replace(' ', '_')\n",
    "        \n",
    "        # image_path에서 '../' 제거\n",
    "        all_data['image_path'] = all_data['image_path'].str.replace(r'^\\.\\./', '', regex=True)\n",
    "\n",
    "        # CSV 파일로 저장\n",
    "        all_data.to_csv(os.path.join('../dataset/', output_file), index=False)\n",
    "        print(f\"Data saved to {os.path.join(base_directory, output_file)}\")\n",
    "    else:\n",
    "        print(\"No data to save.\")\n",
    "\n",
    "    return dataframes if dataframes else None\n",
    "\n",
    "base_directory = \"../dataset/meat_dataset/\"\n",
    "label_directory = \"../dataset/meat_dataset/labels\"\n",
    "output_file = \"only_new_1112.csv\"\n",
    "\n",
    "# 이미지 파일 경로 설정 (임의의 매칭을 위해 folder_name 대신 다른 키 사용 가능)\n",
    "image_directories = {\n",
    "    '20240904': os.path.join(base_directory, '20240904/240904_개체사진'),\n",
    "    '20240905': os.path.join(base_directory, '20240905/240905_개체사진'),\n",
    "    '20240906': os.path.join(base_directory, '20240906/240906_개체사진'),\n",
    "    '20240910': os.path.join(base_directory, '20240910/240910_개체사진'),\n",
    "    '20240912': os.path.join(base_directory, '20240912/240912_개체사진'),\n",
    "    '20240924': os.path.join(base_directory, '20240924/240924_개체사진'),\n",
    "    '20240926': os.path.join(base_directory, '20240926/240926_개체사진'),\n",
    "    '20240927': os.path.join(base_directory, '20240927/240927_개체사진'),\n",
    "    '20241008': os.path.join(base_directory, '20241008/241008_개체사진'),\n",
    "    '20241011': os.path.join(base_directory, '20241011/241011_개체사진'),\n",
    "    '20241015': os.path.join(base_directory, '20241015/241015_개체사진'),\n",
    "    '20241016': os.path.join(base_directory, '20241016/241016_개체사진'),\n",
    "    '20241017': os.path.join(base_directory, '20241017/241017_개체사진'),\n",
    "    '20241018': os.path.join(base_directory, '20241018/241018_개체사진'),\n",
    "    '20241022': os.path.join(base_directory, '20241022/241022_개체사진'),\n",
    "    '20241023': os.path.join(base_directory, '20241023/241023_개체사진'),\n",
    "    '20241024': os.path.join(base_directory, '20241024/241024_개체사진'),\n",
    "    '20241029': os.path.join(base_directory, '20241029/241029_개체사진'),\n",
    "    '20241030': os.path.join(base_directory, '20241030/241030_개체사진'),\n",
    "    '20241031': os.path.join(base_directory, '20241031/241031_개체사진'),\n",
    "    '20241101': os.path.join(base_directory, '20241101/241101_개체사진'),\n",
    "    '20241105': os.path.join(base_directory, '20241105/241105_개체사진'),\n",
    "    '20241106': os.path.join(base_directory, '20241106/241106_개체사진'),\n",
    "    '20241107': os.path.join(base_directory, '20241107/241107_개체사진'),\n",
    "    '20241108': os.path.join(base_directory, '20241108/241108_개체사진'),\n",
    "    '20241112': os.path.join(base_directory, '20241112/241112_개체사진')\n",
    "}\n",
    "\n",
    "# 엑셀 파일 경로 설정\n",
    "excel_files = {\n",
    "    '20240904': os.path.join(label_directory, '횡성KC_실촬영본_240904.xlsx'),\n",
    "    '20240905': os.path.join(label_directory, '횡성KC_실촬영본_240905.xlsx'),\n",
    "    '20240906': os.path.join(label_directory, '횡성KC_실촬영본_240906.xlsx'),\n",
    "    '20240910': os.path.join(label_directory, '횡성KC_실촬영본_240910.xlsx'),\n",
    "    '20240912': os.path.join(label_directory, '횡성KC_실촬영본_240912.xlsx'),\n",
    "    '20240924': os.path.join(label_directory, '횡성KC_실촬영본_240924.xlsx'),\n",
    "    '20240926': os.path.join(label_directory, '횡성KC_실촬영본_240926.xlsx'),\n",
    "    '20240927': os.path.join(label_directory, '횡성KC_실촬영본_240927.xlsx'),\n",
    "    '20241008': os.path.join(label_directory, '횡성KC_실촬영본_241008.xlsx'),\n",
    "    '20241011': os.path.join(label_directory, '횡성KC_실촬영본_241011.xlsx'),\n",
    "    '20241015': os.path.join(label_directory, '횡성KC_실촬영본_241015.xlsx'),\n",
    "    '20241016': os.path.join(label_directory, '횡성KC_실촬영본_241016.xlsx'),\n",
    "    '20241017': os.path.join(label_directory, '횡성KC_실촬영본_241017.xlsx'),\n",
    "    '20241018': os.path.join(label_directory, '횡성KC_실촬영본_241018.xlsx'),\n",
    "    '20241022': os.path.join(label_directory, '횡성KC_실촬영본_241022.xlsx'),\n",
    "    '20241023': os.path.join(label_directory, '횡성KC_실촬영본_241023.xlsx'),\n",
    "    '20241024': os.path.join(label_directory, '횡성KC_실촬영본_241024.xlsx'),\n",
    "    '20241029': os.path.join(label_directory, '횡성KC_실촬영본_241029.xlsx'),\n",
    "    '20241030': os.path.join(label_directory, '횡성KC_실촬영본_241030.xlsx'),\n",
    "    '20241031': os.path.join(label_directory, '횡성KC_실촬영본_241031.xlsx'),\n",
    "    '20241101': os.path.join(label_directory, '횡성KC_실촬영본_241101.xlsx'),\n",
    "    '20241105': os.path.join(label_directory, '횡성KC_실촬영본_241105.xlsx'),\n",
    "    '20241106': os.path.join(label_directory, '횡성KC_실촬영본_241106.xlsx'),\n",
    "    '20241107': os.path.join(label_directory, '횡성KC_실촬영본_241107.xlsx'),\n",
    "    '20241108': os.path.join(label_directory, '횡성KC_실촬영본_241108.xlsx'),\n",
    "    '20241112': os.path.join(label_directory, '횡성KC_실촬영본_241112.xlsx')\n",
    "}\n",
    "\n",
    "processed_data = process_data(base_directory, image_directories, excel_files, output_file)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
