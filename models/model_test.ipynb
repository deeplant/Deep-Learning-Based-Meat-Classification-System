{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import mlflow\n",
    "import mlflow.pytorch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Added to sys.path: /home/work/Deeplant-AI/Deeplant-AI-main\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "\n",
    "# 추가하고자 하는 경로\n",
    "directory_to_add = \"/home/work/Deeplant-AI/Deeplant-AI-main\"\n",
    "\n",
    "# 절대 경로로 변환\n",
    "absolute_path = os.path.abspath(directory_to_add)\n",
    "\n",
    "# sys.path에 경로 추가\n",
    "if absolute_path not in sys.path:\n",
    "    sys.path.append(directory_to_add)\n",
    "\n",
    "print(f\"Added to sys.path: {absolute_path}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "mlflow.set_tracking_uri('http://0.0.0.0:5000')\n",
    "model_uri = \"models:/resnetv2.101x3/2\"\n",
    "\n",
    "model = mlflow.pytorch.load_model(model_uri)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layer(\n",
      "  (base_model): BaseModel(\n",
      "    (base_model): ResNetV2(\n",
      "      (stem): Sequential(\n",
      "        (conv): StdConv2d(3, 192, kernel_size=(7, 7), stride=(2, 2), padding=(3, 3), bias=False)\n",
      "        (pad): ConstantPad2d(padding=(1, 1, 1, 1), value=0.0)\n",
      "        (pool): MaxPool2d(kernel_size=3, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "      )\n",
      "      (stages): Sequential(\n",
      "        (0): ResNetStage(\n",
      "          (blocks): Sequential(\n",
      "            (0): PreActBottleneck(\n",
      "              (downsample): DownsampleConv(\n",
      "                (conv): StdConv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm): Identity()\n",
      "              )\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(192, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (1): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (2): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(768, 192, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(192, 192, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 192, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(192, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): ResNetStage(\n",
      "          (blocks): Sequential(\n",
      "            (0): PreActBottleneck(\n",
      "              (downsample): DownsampleConv(\n",
      "                (conv): StdConv2d(768, 1536, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (norm): Identity()\n",
      "              )\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(768, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(384, 384, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (1): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (2): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (3): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(1536, 384, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(384, 384, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 384, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(384, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): ResNetStage(\n",
      "          (blocks): Sequential(\n",
      "            (0): PreActBottleneck(\n",
      "              (downsample): DownsampleConv(\n",
      "                (conv): StdConv2d(1536, 3072, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (norm): Identity()\n",
      "              )\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(1536, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (1): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (2): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (3): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (4): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (5): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (6): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (7): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (8): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (9): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (10): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (11): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (12): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (13): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (14): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (15): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (16): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (17): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (18): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (19): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (20): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (21): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (22): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 768, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(768, 768, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 768, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(768, 3072, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): ResNetStage(\n",
      "          (blocks): Sequential(\n",
      "            (0): PreActBottleneck(\n",
      "              (downsample): DownsampleConv(\n",
      "                (conv): StdConv2d(3072, 6144, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                (norm): Identity()\n",
      "              )\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 3072, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(3072, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(1536, 1536, kernel_size=(3, 3), stride=(2, 2), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (1): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 6144, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "            (2): PreActBottleneck(\n",
      "              (norm1): GroupNormAct(\n",
      "                32, 6144, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv1): StdConv2d(6144, 1536, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (norm2): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv2): StdConv2d(1536, 1536, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "              (norm3): GroupNormAct(\n",
      "                32, 1536, eps=1e-05, affine=True\n",
      "                (drop): Identity()\n",
      "                (act): ReLU(inplace=True)\n",
      "              )\n",
      "              (conv3): StdConv2d(1536, 6144, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "              (drop_path): Identity()\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): GroupNormAct(\n",
      "        32, 6144, eps=1e-05, affine=True\n",
      "        (drop): Identity()\n",
      "        (act): ReLU(inplace=True)\n",
      "      )\n",
      "      (head): ClassifierHead(\n",
      "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (fc): Identity()\n",
      "        (flatten): Flatten(start_dim=1, end_dim=-1)\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_heads): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=6144, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "        \n",
    "        #self.base_model.conv_head = nn.Identity()\n",
    "        #self.base_model.norm_head = nn.Identity()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.num_features = self.base_model.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        base_output = self.base_model(x)\n",
    "\n",
    "        print(self.num_features)\n",
    "        print(base_output.shape)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "def create_model(model_name, pretrained, num_classes, in_chans, out_dim):\n",
    "\n",
    "    if out_dim <= 0:\n",
    "        raise ValueError(\"오류: out_dim이 0 이하입니다.\")\n",
    "\n",
    "    base_model = BaseModel(model_name, pretrained, num_classes, in_chans)\n",
    "    model = MLP_layer(base_model, out_dim)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "681109b4a19941868f634da11404d93e",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/114M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layer(\n",
      "  (base_model): BaseModel(\n",
      "    (base_model): SwinTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (0): SwinTransformerStage(\n",
      "          (downsample): Identity()\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.009)\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.009)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.018)\n",
      "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.018)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.027)\n",
      "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.027)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.036)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.036)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.045)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.045)\n",
      "            )\n",
      "            (2): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.055)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.055)\n",
      "            )\n",
      "            (3): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.064)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.064)\n",
      "            )\n",
      "            (4): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.073)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.073)\n",
      "            )\n",
      "            (5): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.082)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.082)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.091)\n",
      "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.091)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.100)\n",
      "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.100)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (head): ClassifierHead(\n",
      "        (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (fc): Linear(in_features=768, out_features=5, bias=True)\n",
      "        (flatten): Identity()\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (mlp_heads): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n",
      "torch.Size([5, 3, 224, 224])\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768\n",
      "torch.Size([5, 5])\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (5x5 and 768x64)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[2], line 7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[1;32m      6\u001b[0m     sample_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m5\u001b[39m, \u001b[38;5;241m3\u001b[39m, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)  \u001b[38;5;66;03m# 일반적인 입력 크기\u001b[39;00m\n\u001b[0;32m----> 7\u001b[0m     base_output \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43msample_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      8\u001b[0m     num_features \u001b[38;5;241m=\u001b[39m base_output\u001b[38;5;241m.\u001b[39mshape[\u001b[38;5;241m1\u001b[39m]  \u001b[38;5;66;03m# 출력 크기의 두 번째 차원이 feature 크기\u001b[39;00m\n\u001b[1;32m      9\u001b[0m     \u001b[38;5;28mprint\u001b[39m(num_features)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36mMLP_layer.forward\u001b[0;34m(self, x)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     43\u001b[0m features \u001b[38;5;241m=\u001b[39m base_output\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [head(features) \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_heads]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "Cell \u001b[0;32mIn[1], line 45\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28mprint\u001b[39m(base_output\u001b[38;5;241m.\u001b[39mshape)\n\u001b[1;32m     43\u001b[0m features \u001b[38;5;241m=\u001b[39m base_output\n\u001b[0;32m---> 45\u001b[0m outputs \u001b[38;5;241m=\u001b[39m [\u001b[43mhead\u001b[49m\u001b[43m(\u001b[49m\u001b[43mfeatures\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m head \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mmlp_heads]\n\u001b[1;32m     47\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mcat(outputs, dim\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1\u001b[39m)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/container.py:216\u001b[0m, in \u001b[0;36mSequential.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    214\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m):\n\u001b[1;32m    215\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m module \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m:\n\u001b[0;32m--> 216\u001b[0m         \u001b[38;5;28minput\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[43mmodule\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m)\u001b[49m\n\u001b[1;32m    217\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28minput\u001b[39m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (5x5 and 768x64)"
     ]
    }
   ],
   "source": [
    "model = create_model(\"swin_tiny_patch4_window7_224\", True, 5, 3, 5)\n",
    "\n",
    "print(model)\n",
    "\n",
    "with torch.no_grad():\n",
    "    sample_input = torch.randn(5, 3, 224, 224)  # 일반적인 입력 크기\n",
    "    base_output = model(sample_input)\n",
    "    num_features = base_output.shape[1]  # 출력 크기의 두 번째 차원이 feature 크기\n",
    "    print(num_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_dim, out_dim):\n",
    "    return torch.nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(out_dim)\n",
    "    )\n",
    "\n",
    "class Affine(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones([1, dim, 1, 1]))\n",
    "        self.beta = nn.Parameter(torch.zeros([1, dim, 1, 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.alpha + self.beta\n",
    "\n",
    "class SOPE(nn.Module):\n",
    "    def __init__(self, patch_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.pre_affine = Affine(3)\n",
    "        self.post_affine = Affine(embed_dim)\n",
    "\n",
    "        if patch_size[0] == 16:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim // 8),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 8, embed_dim // 4),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 4, embed_dim // 2),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 2, embed_dim),\n",
    "            )\n",
    "        elif patch_size[0] == 4:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim // 2),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 2, embed_dim),\n",
    "            )\n",
    "        elif patch_size[0] == 2:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim),\n",
    "                nn.GELU(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.pre_affine(x)\n",
    "        x = self.proj(x)\n",
    "        x = self.post_affine(x)\n",
    "        Hp, Wp = x.shape[2], x.shape[3]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DAFF(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, hid_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(hid_dim, hid_dim, kernel_size=3, stride=1, padding=(kernel_size-1)//2, groups=hid_dim)\n",
    "        self.conv3 = nn.Conv2d(hid_dim, out_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.act = nn.GELU()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.compress = nn.Linear(in_dim, in_dim // 4)\n",
    "        self.excitation = nn.Linear(in_dim // 4, in_dim)\n",
    "        self.bn1 = nn.BatchNorm2d(hid_dim)\n",
    "        self.bn2 = nn.BatchNorm2d(hid_dim)\n",
    "        self.bn3 = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.size()\n",
    "        cls_token, tokens = torch.split(x, [1, N-1], dim=1)\n",
    "        x = tokens.reshape(B, int(math.sqrt(N-1)), int(math.sqrt(N-1)), C).permute(0, 3, 1, 2)\n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        x = x + self.act(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        weight = self.squeeze(x).flatten(1).reshape(B, 1, C)\n",
    "        weight = self.excitation(self.act(self.compress(weight)))\n",
    "        cls_token = cls_token * weight\n",
    "        tokens = x.flatten(2).permute(0, 2, 1)\n",
    "        out = torch.cat((cls_token, tokens), dim=1)\n",
    "        return out\n",
    "    \n",
    "class SelectAdaptivePool2d(nn.Module):\n",
    "    def __init__(self, pool_type='avg', flatten=True):\n",
    "        super(SelectAdaptivePool2d, self).__init__()\n",
    "        if pool_type == 'avg':\n",
    "            self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive Average Pooling\n",
    "        elif pool_type == 'max':\n",
    "            self.pool = nn.AdaptiveMaxPool2d((1, 1))  # Adaptive Max Pooling\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported pool_type: {}\".format(pool_type))\n",
    "        \n",
    "        self.flatten = flatten\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 7, 7, 768)\n",
    "        x = x.permute(0, 3, 1, 2)  # Change to (batch_size, 768, 7, 7)\n",
    "        x = self.pool(x)  # Pooling to (batch_size, 768, 1, 1)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.size(0), -1)  # Flatten to (batch_size, 768)\n",
    "        return x \n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans, embed_layer=SOPE):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "        \n",
    "        self.base_model.head.global_pool = nn.Identity()\n",
    "        self.global_pool = SelectAdaptivePool2d()\n",
    "        \n",
    "#         self.base_model.patch_embed = SOPE(patch_size=(16, 16), embed_dim=768)\n",
    "#         for i in range(len(self.base_model.blocks)):\n",
    "#             block = self.base_model.blocks[i]\n",
    "#             in_features = block.mlp.fc1.in_features\n",
    "#             hidden_features = block.mlp.fc1.out_features\n",
    "#             out_features = block.mlp.fc2.out_features\n",
    "\n",
    "#             # DAFF 모듈로 교체\n",
    "#             block.mlp = DAFF(in_features, hidden_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 패치 임베딩\n",
    "#         x = self.base_model.patch_embed(x)\n",
    "#         print(f\"After patch embedding: {x.shape}\")  # (batch_size, num_patches, embed_dim)\n",
    "\n",
    "#         # 클래스 토큰 추가\n",
    "#         batch_size = x.shape[0]\n",
    "#         print(\"before:\", self.base_model.cls_token.shape)\n",
    "#         cls_token = self.base_model.cls_token.expand(batch_size, -1, -1)  # (batch_size, 1, embed_dim)\n",
    "#         print(\"after:\", cls_token.shape)\n",
    "#         x = torch.cat((cls_token, x), dim=1)  # (batch_size, num_patches + 1, embed_dim)\n",
    "#         print(f\"After adding class token: {x.shape}\")\n",
    "        \n",
    "#         # 포지셔널 임베딩 추가\n",
    "#         x = x + self.base_model.pos_embed  # (batch_size, num_patches + 1, embed_dim)\n",
    "#         x = self.base_model.pos_drop(x)\n",
    "#         print(f\"After positional embedding: {x.shape}\")\n",
    "        \n",
    "#         # 트랜스포머 블록 통과\n",
    "#         x = self.base_model.blocks(x)\n",
    "#         print(f\"After transformer blocks: {x.shape}\")\n",
    "        \n",
    "#         # LayerNorm 적용\n",
    "#         x = self.base_model.norm(x)\n",
    "#         print(f\"After norm: {x.shape}\")\n",
    "        \n",
    "#         # Class token 선택\n",
    "#         cls_token_final = x[:, 0]\n",
    "#         print(f\"After selecting class token: {cls_token_final.shape}\")\n",
    "        \n",
    "#         # Classifier head 적용\n",
    "#         x = self.base_model.head(cls_token_final)\n",
    "#         print(f\"Final output shape: {x.shape}\")\n",
    "\n",
    "        x = self.base_model.patch_embed(x)\n",
    "        print(f\"After patch embedding: {x.shape}\")  # (batch_size, num_patches, embed_dim)\n",
    "        \n",
    "        x = self.base_model.layers(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.base_model.norm(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        print(\"before global pool:\", x.shape)\n",
    "        x = self.global_pool(x)\n",
    "        print(\"after:\", x.shape)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.num_features = self.base_model.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        \n",
    "        print(\"mlp input:\", base_output.shape)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, pretrained, num_classes, in_chans, out_dim):\n",
    "\n",
    "    if out_dim <= 0:\n",
    "        raise ValueError(\"오류: out_dim이 0 이하입니다.\")\n",
    "\n",
    "    base_model = BaseModel(model_name, pretrained, num_classes, in_chans)\n",
    "    model = MLP_layer(base_model, out_dim)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "ab649cb04d8545cb8d62f9cb80a12ad6",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "model.safetensors:   0%|          | 0.00/295M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layer(\n",
      "  (base_model): BaseModel(\n",
      "    (base_model): SwinTransformer(\n",
      "      (patch_embed): PatchEmbed(\n",
      "        (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "        (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "      )\n",
      "      (layers): Sequential(\n",
      "        (0): SwinTransformerStage(\n",
      "          (downsample): Identity()\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): Identity()\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): Identity()\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.003)\n",
      "              (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.003)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (1): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.006)\n",
      "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.006)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.009)\n",
      "              (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.009)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (2): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.011)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.011)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.014)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.014)\n",
      "            )\n",
      "            (2): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.017)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.017)\n",
      "            )\n",
      "            (3): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.020)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.020)\n",
      "            )\n",
      "            (4): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.023)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.023)\n",
      "            )\n",
      "            (5): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.026)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.026)\n",
      "            )\n",
      "            (6): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.029)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.029)\n",
      "            )\n",
      "            (7): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.031)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.031)\n",
      "            )\n",
      "            (8): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.034)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.034)\n",
      "            )\n",
      "            (9): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.037)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.037)\n",
      "            )\n",
      "            (10): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.040)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.040)\n",
      "            )\n",
      "            (11): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.043)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.043)\n",
      "            )\n",
      "            (12): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.046)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.046)\n",
      "            )\n",
      "            (13): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.049)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.049)\n",
      "            )\n",
      "            (14): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.051)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.051)\n",
      "            )\n",
      "            (15): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.054)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.054)\n",
      "            )\n",
      "            (16): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.057)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.057)\n",
      "            )\n",
      "            (17): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.060)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.060)\n",
      "            )\n",
      "            (18): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.063)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.063)\n",
      "            )\n",
      "            (19): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.066)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.066)\n",
      "            )\n",
      "            (20): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.069)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.069)\n",
      "            )\n",
      "            (21): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.071)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.071)\n",
      "            )\n",
      "            (22): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.074)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.074)\n",
      "            )\n",
      "            (23): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.077)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.077)\n",
      "            )\n",
      "            (24): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.080)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.080)\n",
      "            )\n",
      "            (25): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.083)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.083)\n",
      "            )\n",
      "            (26): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.086)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.086)\n",
      "            )\n",
      "            (27): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.089)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.089)\n",
      "            )\n",
      "            (28): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.091)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.091)\n",
      "            )\n",
      "            (29): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.094)\n",
      "              (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.094)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (3): SwinTransformerStage(\n",
      "          (downsample): PatchMerging(\n",
      "            (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "            (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "          )\n",
      "          (blocks): Sequential(\n",
      "            (0): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.097)\n",
      "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.097)\n",
      "            )\n",
      "            (1): SwinTransformerBlock(\n",
      "              (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (attn): WindowAttention(\n",
      "                (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "                (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "                (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "                (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "                (softmax): Softmax(dim=-1)\n",
      "              )\n",
      "              (drop_path1): DropPath(drop_prob=0.100)\n",
      "              (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "              (mlp): Mlp(\n",
      "                (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "                (act): GELU(approximate='none')\n",
      "                (drop1): Dropout(p=0.0, inplace=False)\n",
      "                (norm): Identity()\n",
      "                (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "                (drop2): Dropout(p=0.0, inplace=False)\n",
      "              )\n",
      "              (drop_path2): DropPath(drop_prob=0.100)\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "      (head): ClassifierHead(\n",
      "        (global_pool): Identity()\n",
      "        (drop): Dropout(p=0.0, inplace=False)\n",
      "        (fc): Identity()\n",
      "        (flatten): Identity()\n",
      "      )\n",
      "    )\n",
      "    (global_pool): SelectAdaptivePool2d(\n",
      "      (pool): AdaptiveAvgPool2d(output_size=(1, 1))\n",
      "    )\n",
      "  )\n",
      "  (mlp_heads): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'swin_s3_base_224'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "model = create_model(model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !export PYTHONPATH=$PYTHONPATH:/home/work/tiny-transformers/tiny-transformers\n",
    "\n",
    "# +\n",
    "# from pycls.models.cnns.resnet import ResNet  # resnet.py에서 ResNet 모델 불러오기\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, model_name='vit_base_r50_s16_224.orig_in21k', pretrained=True, num_classes=0, load_from_file=False, model_path=None):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.model = None\n",
    "        self.features = []\n",
    "        self.feature_layers = ['patch_embed', 'blocks.5', 'blocks.10', 'norm']  # Hook after key transformer blocks\n",
    "\n",
    "        if load_from_file and model_path:\n",
    "            # Load model from a saved .pth file\n",
    "            self._load_pretrained_model(model_path)\n",
    "        else:\n",
    "            # Use timm to create a model\n",
    "            self.model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _load_pretrained_model(self, model_path):\n",
    "        # Load the saved model from the provided path\n",
    "        print(f\"Loading teacher model from {model_path}\")\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        # self.model.load_state_dict(checkpoint, strict=False)\n",
    "        # self.model = nn.Sequential(*list(checkpoint['model'].children())[:-1])  # Assuming last two layers are not required\n",
    "        # self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        # Check if the checkpoint is a full model or just a state dict\n",
    "        if 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']  # If saved as a state dict\n",
    "        else:\n",
    "            state_dict = checkpoint  # If it's directly the state dict\n",
    "\n",
    "        # Initialize timm model\n",
    "        self.model = timm.create_model(model_name='vit_base_r50_s16_224.orig_in21k', pretrained=False, num_classes=0)\n",
    "        \n",
    "        # Adjust the state dict keys if necessary (remove 'base_model.base_model.')\n",
    "        new_state_dict = {}\n",
    "        for key in state_dict.keys():\n",
    "            new_key = key.replace('base_model.base_model.', 'model.')  # Adjust the prefix\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "        # Load state dict into model\n",
    "        self.model.load_state_dict(new_state_dict, strict=False)\n",
    "        print(\"Teacher model loaded successfully!\")\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.features.append(output)\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name in self.feature_layers:\n",
    "                module.register_forward_hook(hook)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        output = self.model(x)\n",
    "        return output, self.features\n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "        self.features = []\n",
    "        self.feature_layers = ['layers.0', 'layers.1', 'layers.2', 'layers.3']  # Hook SwinTransformerStage blocks\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.features.append(output)\n",
    "\n",
    "        \n",
    "        for name, module in self.base_model.named_modules():\n",
    "            if name in self.feature_layers:\n",
    "                module.register_forward_hook(hook)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        output = self.base_model(x)\n",
    "        return output, self.features\n",
    "\n",
    "class FeatureTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FeatureTransform, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 입력이 [B, H, W, C] 형태라면 [B, C, H, W]로 변환\n",
    "        if x.dim() == 4 and x.shape[1] != x.shape[-1]:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "class DistillationModel(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model):\n",
    "        super(DistillationModel, self).__init__()\n",
    "        self.teacher_model = teacher_model\n",
    "        self.student_model = student_model\n",
    "        self.output_transform = nn.Linear(768, 5)\n",
    "        self.transforms = None  # 초기에는 None으로 설정\n",
    "\n",
    "    def forward(self, x):\n",
    "        # print(\"DistillationModel forward pass started\", flush=True)\n",
    "\n",
    "        device = x.device  # Get the device of the input tensor\n",
    "\n",
    "        with torch.no_grad():\n",
    "            teacher_output, teacher_features = self.teacher_model(x)  # Teacher features remain frozen.\n",
    "    \n",
    "        student_output, student_features = self.student_model(x)  # Student features should be updated.\n",
    "\n",
    "        # transforms가 아직 초기화되지 않았다면 여기서 초기화\n",
    "        if self.transforms is None:\n",
    "            self.transforms = nn.ModuleList()\n",
    "            for t_feat, s_feat in zip(teacher_features, student_features[:-1]):\n",
    "                in_channels = s_feat.shape[-1]  # Student feature 채널 수\n",
    "                out_channels = t_feat.shape[1]  # Teacher feature 채널 수\n",
    "                transform = FeatureTransform(in_channels, out_channels)\n",
    "                self.transforms.append(transform.to(device))  # Move the transform to the correct device\n",
    "\n",
    "\n",
    "        # 손실 및 변환을 동시에 계산\n",
    "        distillation_loss = torch.tensor(0.0, device=device, requires_grad=True)  # 초기화\n",
    "        for i, (transform, s_feat, t_feat) in enumerate(zip(self.transforms, student_features[:-1], teacher_features)):\n",
    "            # print(f\"Layer {i+1} - Before Transformation - Student feature shape: {s_feat.shape}\")\n",
    "            # print(f\"Before Conv: {s_feat.shape}\", flush=True)\n",
    "            \n",
    "            # 학생 특징 변환\n",
    "            transformed_feat = transform(s_feat)  # permute 필요 없음\n",
    "            # print(f\"Layer {i+1} - After Transformation - Transformed feat shape: {transformed_feat.shape}\", flush=True)\n",
    "\n",
    "            # 손실 계산\n",
    "            layer_loss = F.mse_loss(transformed_feat, t_feat)\n",
    "            distillation_loss = distillation_loss + layer_loss\n",
    "            # print(f\"Layer {i+1} loss: {layer_loss.item()}\", flush=True)\n",
    "\n",
    "        student_output_resized = self.output_transform(student_output)\n",
    "        return student_output_resized, teacher_output, distillation_loss\n",
    "\n",
    "\n",
    "\n",
    "# # MLP Layer to output 'out_dim' different outputs\n",
    "# class MLP_layer(nn.Module):\n",
    "#     def __init__(self, base_model, out_dim):\n",
    "#         super().__init__()\n",
    "#         self.base_model = base_model\n",
    "#         self.out_dim = out_dim\n",
    "\n",
    "#         # Get the number of features from the base model\n",
    "#         self.num_features = self.base_model.base_model.num_features\n",
    "\n",
    "#         # Create MLP heads, one for each output dimension (out_dim = 5 in this case)\n",
    "#         self.mlp_heads = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(self.num_features, 64),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(64, 1)\n",
    "#             ) for _ in range(out_dim)\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         base_output = self.base_model(x)\n",
    "#         features = base_output\n",
    "\n",
    "#         # Apply each MLP head to the base model output\n",
    "#         outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "#         # Concatenate the outputs along the last dimension\n",
    "#         return torch.cat(outputs, dim=1)\n",
    "\n",
    "def create_model(student_model_name, teacher_model_name, pretrained, num_classes, in_chans, out_dim, load_from_file=False, model_path=None):\n",
    "    teacher_model = TeacherModel(model_name=teacher_model_name, pretrained=pretrained, num_classes=num_classes, load_from_file=load_from_file, model_path=model_path)\n",
    "    student_model = StudentModel(model_name=student_model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "    model = DistillationModel(teacher_model, student_model)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [],
   "source": [
    "#custom model\n",
    "\n",
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# !export PYTHONPATH=$PYTHONPATH:/home/work/tiny-transformers/tiny-transformers\n",
    "\n",
    "# +\n",
    "# from pycls.models.cnns.resnet import ResNet  # resnet.py에서 ResNet 모델 불러오기\n",
    "\n",
    "class TeacherModel(nn.Module):\n",
    "    def __init__(self, model_name='resnet50', pretrained=True, num_classes=0, load_from_file=False, model_path=None):\n",
    "        super(TeacherModel, self).__init__()\n",
    "        self.model = None\n",
    "        self.features = []\n",
    "        self.feature_layers = ['layer1', 'layer2', 'layer3']\n",
    "\n",
    "        if load_from_file and model_path:\n",
    "            # Load model from a saved .pth file\n",
    "            self._load_pretrained_model(model_path)\n",
    "        else:\n",
    "            # Use timm to create a model\n",
    "            self.model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "        \n",
    "        self.model.eval()\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _load_pretrained_model(self, model_path):\n",
    "        # Load the saved model from the provided path\n",
    "        print(f\"Loading teacher model from {model_path}\")\n",
    "        checkpoint = torch.load(model_path, map_location=torch.device('cpu'))\n",
    "        # self.model.load_state_dict(checkpoint, strict=False)\n",
    "        # self.model = nn.Sequential(*list(checkpoint['model'].children())[:-1])  # Assuming last two layers are not required\n",
    "        # self.model.load_state_dict(checkpoint['state_dict'])\n",
    "        # Check if the checkpoint is a full model or just a state dict\n",
    "        if 'state_dict' in checkpoint:\n",
    "            state_dict = checkpoint['state_dict']  # If saved as a state dict\n",
    "        else:\n",
    "            state_dict = checkpoint  # If it's directly the state dict\n",
    "\n",
    "        # Initialize timm model\n",
    "        self.model = timm.create_model(model_name='resnet50', pretrained=False, num_classes=0)\n",
    "        \n",
    "        # Adjust the state dict keys if necessary (remove 'base_model.base_model.')\n",
    "        new_state_dict = {}\n",
    "        for key in state_dict.keys():\n",
    "            new_key = key.replace('base_model.base_model.', 'model.')  # Adjust the prefix\n",
    "            new_state_dict[new_key] = state_dict[key]\n",
    "\n",
    "        # Load state dict into model\n",
    "        self.model.load_state_dict(new_state_dict, strict=False)\n",
    "        print(\"Teacher model loaded successfully!\")\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.features.append(output)\n",
    "\n",
    "        for name, module in self.model.named_modules():\n",
    "            if name in self.feature_layers:\n",
    "                module.register_forward_hook(hook)\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        output = self.model(x)\n",
    "        return output, self.features\n",
    "\n",
    "\n",
    "class StudentModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(StudentModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "        self.features = []\n",
    "        self.feature_layers = ['layers.0', 'layers.1', 'layers.2', 'layers.3']  # Hook SwinTransformerStage blocks\n",
    "        self._register_hooks()\n",
    "\n",
    "    def _register_hooks(self):\n",
    "        def hook(module, input, output):\n",
    "            self.features.append(output)\n",
    "\n",
    "        \n",
    "        for name, module in self.base_model.named_modules():\n",
    "            if name in self.feature_layers:\n",
    "                module.register_forward_hook(hook)\n",
    "\n",
    "\n",
    "    def forward(self, x):\n",
    "        self.features = []\n",
    "        output = self.base_model(x)\n",
    "        return output, self.features\n",
    "\n",
    "class FeatureTransform(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels):\n",
    "        super(FeatureTransform, self).__init__()\n",
    "        self.conv = nn.Conv2d(in_channels, out_channels, kernel_size=1)\n",
    "    \n",
    "    def forward(self, x):\n",
    "        # 입력이 [B, H, W, C] 형태라면 [B, C, H, W]로 변환\n",
    "        if x.dim() == 4 and x.shape[1] != x.shape[-1]:\n",
    "            x = x.permute(0, 3, 1, 2)\n",
    "        \n",
    "        x = self.conv(x)\n",
    "        \n",
    "        \n",
    "        return x\n",
    "\n",
    "\n",
    "\n",
    "class DistillationModel(nn.Module):\n",
    "    def __init__(self, teacher_model, student_model, beta=1.0):\n",
    "        super(DistillationModel, self).__init__()\n",
    "        self.teacher_model = teacher_model\n",
    "        self.student_model = student_model\n",
    "        self.output_transform = nn.Linear(768, 5)\n",
    "        self.transforms = None\n",
    "        self.beta = beta  # beta 값을 클래스 인스턴스 변수로 저장\n",
    "\n",
    "    def forward(self, x, labels=None):\n",
    "        device = x.device\n",
    "\n",
    "        # Teacher 모델에서 feature 추출\n",
    "        with torch.no_grad():\n",
    "            teacher_output, teacher_features = self.teacher_model(x)\n",
    "\n",
    "        # Student 모델에서 feature 추출\n",
    "        student_output, student_features = self.student_model(x)\n",
    "\n",
    "        # Feature Alignment\n",
    "        if self.transforms is None:\n",
    "            self.transforms = nn.ModuleList([\n",
    "                FeatureTransform(s_feat.shape[-1], t_feat.shape[1]).to(device)\n",
    "                for t_feat, s_feat in zip(teacher_features, student_features[:-1])\n",
    "            ])\n",
    "\n",
    "        # Distillation loss (guidance loss) 계산\n",
    "        distillation_loss = torch.tensor(0.0, device=device)\n",
    "        for transform, s_feat, t_feat in zip(self.transforms, student_features[:-1], teacher_features):\n",
    "            s_feat_resized = transform(s_feat)\n",
    "            distillation_loss += F.mse_loss(s_feat_resized, t_feat)\n",
    "\n",
    "        # Classification Loss 계산\n",
    "        student_output_resized = self.output_transform(student_output)\n",
    "        classification_loss = F.cross_entropy(student_output_resized, labels) if labels is not None else torch.tensor(0.0, device=device)\n",
    "\n",
    "        # Total Loss 계산\n",
    "        total_loss = classification_loss + self.beta * distillation_loss\n",
    "        return student_output_resized, teacher_output, classification_loss, distillation_loss, total_loss\n",
    "\n",
    "\n",
    "# # MLP Layer to output 'out_dim' different outputs\n",
    "# class MLP_layer(nn.Module):\n",
    "#     def __init__(self, base_model, out_dim):\n",
    "#         super().__init__()\n",
    "#         self.base_model = base_model\n",
    "#         self.out_dim = out_dim\n",
    "\n",
    "#         # Get the number of features from the base model\n",
    "#         self.num_features = self.base_model.base_model.num_features\n",
    "\n",
    "#         # Create MLP heads, one for each output dimension (out_dim = 5 in this case)\n",
    "#         self.mlp_heads = nn.ModuleList([\n",
    "#             nn.Sequential(\n",
    "#                 nn.Linear(self.num_features, 64),\n",
    "#                 nn.ReLU(),\n",
    "#                 nn.Linear(64, 1)\n",
    "#             ) for _ in range(out_dim)\n",
    "#         ])\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         base_output = self.base_model(x)\n",
    "#         features = base_output\n",
    "\n",
    "#         # Apply each MLP head to the base model output\n",
    "#         outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "#         # Concatenate the outputs along the last dimension\n",
    "#         return torch.cat(outputs, dim=1)\n",
    "\n",
    "def create_model(student_model_name, teacher_model_name, pretrained, num_classes, in_chans, out_dim, load_from_file=False, model_path=None):\n",
    "    teacher_model = TeacherModel(model_name=teacher_model_name, pretrained=pretrained, num_classes=num_classes, load_from_file=load_from_file, model_path=model_path)\n",
    "    student_model = StudentModel(model_name=student_model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "    model = DistillationModel(teacher_model, student_model)\n",
    "\n",
    "    return model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After patch embedding: torch.Size([1, 56, 56, 96])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "before global pool: torch.Size([1, 7, 7, 768])\n",
      "after: torch.Size([1, 768])\n",
      "mlp input: torch.Size([1, 768])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[9], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, in_chans, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Pass the input through the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m student_output_resized, teacher_output, distillation_loss \u001b[38;5;241m=\u001b[39m model(random_input)  \u001b[38;5;66;03m# Unpack all three values\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Check the shape of the output\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "tmodel = TeacherModel(model_name=teacher_model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "\n",
    "# 랜덤 입력 생성 (배치 크기 1, 채널 수 3, 이미지 크기 224x224)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# Pass the input through the model\n",
    "student_output_resized, teacher_output, distillation_loss = model(random_input)  # Unpack all three values\n",
    "\n",
    "# Check the shape of the output\n",
    "print(\"Output shape:\", output.shape)\n",
    "\n",
    "# Optionally print the feature maps from intermediate layers\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"Feature {i+1} shape:\", feature.shape)\n",
    "\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After patch embedding: torch.Size([1, 56, 56, 96])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "before global pool: torch.Size([1, 7, 7, 768])\n",
      "after: torch.Size([1, 768])\n",
      "mlp input: torch.Size([1, 768])\n"
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "not enough values to unpack (expected 3, got 1)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[10], line 16\u001b[0m\n\u001b[1;32m     13\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, in_chans, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# Pass the input through the model\u001b[39;00m\n\u001b[0;32m---> 16\u001b[0m student_output_resized, teacher_output, distillation_loss \u001b[38;5;241m=\u001b[39m model(random_input)  \u001b[38;5;66;03m# Unpack all three values\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Check the shape of the output\u001b[39;00m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mOutput shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, output\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: not enough values to unpack (expected 3, got 1)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "smodel = StudentModel(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "\n",
    "# 랜덤 입력 생성 (배치 크기 1, 채널 수 3, 이미지 크기 224x224)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# Pass the input through the model\n",
    "student_output_resized, teacher_output, distillation_loss = model(random_input)  # Unpack all three values\n",
    "\n",
    "# Check the shape of the output\n",
    "print(\"Output shape:\", output.shape)\n",
    "# print(features)\n",
    "# Optionally print the feature maps from intermediate layers\n",
    "for i, feature in enumerate(features):\n",
    "    print(f\"Feature {i+1} shape:\", feature.shape)\n",
    "# print(model.base_model)\n",
    "# print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[45], line 25\u001b[0m\n\u001b[1;32m     22\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, in_chans, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     24\u001b[0m \u001b[38;5;66;03m# 모델에 입력 통과\u001b[39;00m\n\u001b[0;32m---> 25\u001b[0m student_output_resized, teacher_output, distillation_loss \u001b[38;5;241m=\u001b[39m model(random_input)\n\u001b[1;32m     27\u001b[0m \u001b[38;5;66;03m# 출력 shape와 distillation loss 확인\u001b[39;00m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent Output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, student_output_resized\u001b[38;5;241m.\u001b[39mshape)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import timm\n",
    "from torch import nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "# 먼저 TeacherModel, StudentModel, FeatureTransform, DistillationModel 클래스가 \n",
    "# 위에서 제공한 수정된 버전으로 정의되어 있는지 확인해주세요.\n",
    "\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# 모델 새로 생성\n",
    "teacher_model = TeacherModel(model_name=teacher_model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "student_model = StudentModel(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "model = DistillationModel(teacher_model=teacher_model, student_model=student_model)\n",
    "\n",
    "# 랜덤 입력 생성\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# 모델에 입력 통과\n",
    "student_output_resized, teacher_output, distillation_loss = model(random_input)\n",
    "\n",
    "# 출력 shape와 distillation loss 확인\n",
    "print(\"Student Output shape:\", student_output_resized.shape)\n",
    "print(\"Teacher Output shape:\", teacher_output.shape)\n",
    "print(f\"Distillation loss: {distillation_loss}\")\n",
    "\n",
    "# # 중간 특징 맵 출력 및 변환 과정 확인\n",
    "# for i, (transform, student_feature, teacher_feature) in enumerate(zip(model.transforms, model.student_model.features, model.teacher_model.features)):\n",
    "#     print(f\"\\nLayer {i+1}:\")\n",
    "#     print(f\"Student Feature original shape: {student_feature.shape}\")\n",
    "    \n",
    "#     # Student 특징 맵을 [B, C, H, W] 형태로 변환\n",
    "#     student_feature_permuted = student_feature.permute(0, 3, 1, 2)\n",
    "#     print(f\"Student Feature permuted shape: {student_feature_permuted.shape}\")\n",
    "    \n",
    "#     # 변환된 특징 맵\n",
    "#     transformed_feature = transform(student_feature_permuted)\n",
    "#     print(f\"Student Feature transformed shape: {transformed_feature.shape}\")\n",
    "    \n",
    "#     print(f\"Teacher Feature shape: {teacher_feature.shape}\")\n",
    "    \n",
    "#     # Shape 일치 여부 확인\n",
    "#     if transformed_feature.shape == teacher_feature.shape:\n",
    "#         print(\"Shapes match!\")\n",
    "#     else:\n",
    "#         print(\"Shapes do not match.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Student Output shape: torch.Size([1, 5])\n",
      "Teacher Output shape: torch.Size([1, 2048])\n",
      "Total Distillation loss: 22.66550064086914\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# Create distillation model\n",
    "model = create_model(model_name, teacher_model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "model.to('cpu')\n",
    "\n",
    "# Generate random input (batch size = 1, 3 channels, 224x224 image)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# Pass the input through the model\n",
    "student_output_resized, teacher_output, distillation_loss = model(random_input)\n",
    "\n",
    "# Check the shape of the output and distillation loss\n",
    "print(\"Student Output shape:\", student_output_resized.shape)\n",
    "print(\"Teacher Output shape:\", teacher_output.shape)\n",
    "print(f\"Total Distillation loss: {distillation_loss.item()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "create_model() missing 1 required positional argument: 'out_dim'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[34], line 11\u001b[0m\n\u001b[1;32m      8\u001b[0m out_dim \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m5\u001b[39m\n\u001b[1;32m     10\u001b[0m \u001b[38;5;66;03m# 모델 생성\u001b[39;00m\n\u001b[0;32m---> 11\u001b[0m model \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_model\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmodel_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpretrained\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnum_classes\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43min_chans\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mout_dim\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# 랜덤 입력 생성 (배치 크기 1, 채널 수 3, 이미지 크기 224x224)\u001b[39;00m\n\u001b[1;32m     14\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, in_chans, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n",
      "\u001b[0;31mTypeError\u001b[0m: create_model() missing 1 required positional argument: 'out_dim'"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 모델을 생성\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# 모델 생성\n",
    "model = create_model(model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "\n",
    "# 랜덤 입력 생성 (배치 크기 1, 채널 수 3, 이미지 크기 224x224)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# 모델에 랜덤 입력을 넣어 출력 확인\n",
    "output = model(random_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # 출력의 크기 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SwinTransformer(\n",
      "  (patch_embed): PatchEmbed(\n",
      "    (proj): Conv2d(3, 96, kernel_size=(4, 4), stride=(4, 4))\n",
      "    (norm): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "  )\n",
      "  (layers): Sequential(\n",
      "    (0): SwinTransformerStage(\n",
      "      (downsample): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=96, out_features=288, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=96, out_features=96, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.003)\n",
      "          (norm2): LayerNorm((96,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=96, out_features=384, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=384, out_features=96, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.003)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (1): SwinTransformerStage(\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=384, out_features=192, bias=False)\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.006)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.006)\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=192, out_features=576, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=192, out_features=192, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.009)\n",
      "          (norm2): LayerNorm((192,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=192, out_features=768, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=768, out_features=192, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.009)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (2): SwinTransformerStage(\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=768, out_features=384, bias=False)\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.011)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.011)\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.014)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.014)\n",
      "        )\n",
      "        (2): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.017)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.017)\n",
      "        )\n",
      "        (3): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.020)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.020)\n",
      "        )\n",
      "        (4): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.023)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.023)\n",
      "        )\n",
      "        (5): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.026)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.026)\n",
      "        )\n",
      "        (6): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.029)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.029)\n",
      "        )\n",
      "        (7): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.031)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.031)\n",
      "        )\n",
      "        (8): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.034)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.034)\n",
      "        )\n",
      "        (9): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.037)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.037)\n",
      "        )\n",
      "        (10): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.040)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.040)\n",
      "        )\n",
      "        (11): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.043)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.043)\n",
      "        )\n",
      "        (12): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.046)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.046)\n",
      "        )\n",
      "        (13): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.049)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.049)\n",
      "        )\n",
      "        (14): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.051)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.051)\n",
      "        )\n",
      "        (15): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.054)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.054)\n",
      "        )\n",
      "        (16): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.057)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.057)\n",
      "        )\n",
      "        (17): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.060)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.060)\n",
      "        )\n",
      "        (18): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.063)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.063)\n",
      "        )\n",
      "        (19): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.066)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.066)\n",
      "        )\n",
      "        (20): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.069)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.069)\n",
      "        )\n",
      "        (21): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.071)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.071)\n",
      "        )\n",
      "        (22): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.074)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.074)\n",
      "        )\n",
      "        (23): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.077)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.077)\n",
      "        )\n",
      "        (24): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.080)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.080)\n",
      "        )\n",
      "        (25): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.083)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.083)\n",
      "        )\n",
      "        (26): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.086)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.086)\n",
      "        )\n",
      "        (27): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.089)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.089)\n",
      "        )\n",
      "        (28): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.091)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.091)\n",
      "        )\n",
      "        (29): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=384, out_features=1152, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=384, out_features=384, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.094)\n",
      "          (norm2): LayerNorm((384,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=384, out_features=1536, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=1536, out_features=384, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.094)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "    (3): SwinTransformerStage(\n",
      "      (downsample): PatchMerging(\n",
      "        (norm): LayerNorm((1536,), eps=1e-05, elementwise_affine=True)\n",
      "        (reduction): Linear(in_features=1536, out_features=768, bias=False)\n",
      "      )\n",
      "      (blocks): Sequential(\n",
      "        (0): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.097)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.097)\n",
      "        )\n",
      "        (1): SwinTransformerBlock(\n",
      "          (norm1): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (attn): WindowAttention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "            (softmax): Softmax(dim=-1)\n",
      "          )\n",
      "          (drop_path1): DropPath(drop_prob=0.100)\n",
      "          (norm2): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (drop_path2): DropPath(drop_prob=0.100)\n",
      "        )\n",
      "      )\n",
      "    )\n",
      "  )\n",
      "  (norm): LayerNorm((768,), eps=1e-05, elementwise_affine=True)\n",
      "  (head): ClassifierHead(\n",
      "    (global_pool): SelectAdaptivePool2d(pool_type=avg, flatten=Identity())\n",
      "    (drop): Dropout(p=0.0, inplace=False)\n",
      "    (fc): Identity()\n",
      "    (flatten): Identity()\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model = timm.create_model(model_name='swin_s3_base_224', pretrained=True, num_classes=0, in_chans=3)\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (2x5 and 768x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[36], line 31\u001b[0m\n\u001b[1;32m     29\u001b[0m model\u001b[38;5;241m.\u001b[39meval()  \u001b[38;5;66;03m# 평가 모드로 설정 (gradient 업데이트 방지)\u001b[39;00m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 31\u001b[0m     student_output_resized, teacher_output, distillation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_tensor\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;66;03m# 결과 출력\u001b[39;00m\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent Output Resized:\u001b[39m\u001b[38;5;124m\"\u001b[39m, student_output_resized\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[32], line 145\u001b[0m, in \u001b[0;36mDistillationModel.forward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m    142\u001b[0m     guidance_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(s_feat_resized, t_feat)\n\u001b[1;32m    144\u001b[0m \u001b[38;5;66;03m# Classification Loss 계산\u001b[39;00m\n\u001b[0;32m--> 145\u001b[0m student_output_resized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    146\u001b[0m classification_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(student_output_resized, labels) \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    148\u001b[0m \u001b[38;5;66;03m# Total Loss 계산\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (2x5 and 768x5)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 테스트를 위한 설정 값\n",
    "student_model_name = \"swin_tiny_patch4_window7_224\"  # 예: Swin-Tiny\n",
    "teacher_model_name = \"resnet50\"  # 예: ResNet50\n",
    "pretrained = False\n",
    "num_classes = 5\n",
    "in_chans = 3\n",
    "out_dim = 5  # 최종 출력 차원 (예: 5개의 클래스를 예측한다고 가정)\n",
    "load_from_file = False\n",
    "model_path = None\n",
    "\n",
    "# 임의의 입력 데이터 생성 (배치 크기 2, 채널 3, 높이 224, 너비 224)\n",
    "input_tensor = torch.randn(2, in_chans, 224, 224)\n",
    "\n",
    "# 모델 생성\n",
    "model = create_model(\n",
    "    student_model_name=student_model_name,\n",
    "    teacher_model_name=teacher_model_name,\n",
    "    pretrained=pretrained,\n",
    "    num_classes=num_classes,\n",
    "    in_chans=in_chans,\n",
    "    out_dim=out_dim,\n",
    "    load_from_file=load_from_file,\n",
    "    model_path=model_path\n",
    ")\n",
    "\n",
    "# DistillationModel의 forward 테스트\n",
    "model.eval()  # 평가 모드로 설정 (gradient 업데이트 방지)\n",
    "with torch.no_grad():\n",
    "    student_output_resized, teacher_output, distillation_loss = model(input_tensor)\n",
    "\n",
    "# 결과 출력\n",
    "print(\"Student Output Resized:\", student_output_resized.shape)\n",
    "print(\"Teacher Output:\", teacher_output.shape)\n",
    "print(\"Distillation Loss:\", distillation_loss.item())\n",
    "\n",
    "# TeacherModel 및 StudentModel의 feature 확인\n",
    "print(\"\\n--- Feature Shapes ---\")\n",
    "print(\"Teacher Features:\")\n",
    "for i, feat in enumerate(model.teacher_model.features):\n",
    "    print(f\"  Layer {i+1}: {feat.shape}\")\n",
    "\n",
    "print(\"Student Features:\")\n",
    "for i, feat in enumerate(model.student_model.features):\n",
    "    print(f\"  Layer {i+1}: {feat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "mat1 and mat2 shapes cannot be multiplied (1x5 and 768x5)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 17\u001b[0m\n\u001b[1;32m     14\u001b[0m random_input \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mrandn(\u001b[38;5;241m1\u001b[39m, in_chans, \u001b[38;5;241m224\u001b[39m, \u001b[38;5;241m224\u001b[39m)\n\u001b[1;32m     16\u001b[0m \u001b[38;5;66;03m# Pass the input through the model\u001b[39;00m\n\u001b[0;32m---> 17\u001b[0m student_output_resized, teacher_output, distillation_loss \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[43m(\u001b[49m\u001b[43mrandom_input\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     19\u001b[0m \u001b[38;5;66;03m# Check the shape of the output and distillation loss\u001b[39;00m\n\u001b[1;32m     20\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mStudent Output shape:\u001b[39m\u001b[38;5;124m\"\u001b[39m, student_output_resized\u001b[38;5;241m.\u001b[39mshape)\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "Cell \u001b[0;32mIn[28], line 144\u001b[0m, in \u001b[0;36mDistillationModel.forward\u001b[0;34m(self, x, labels)\u001b[0m\n\u001b[1;32m    141\u001b[0m     guidance_loss \u001b[38;5;241m+\u001b[39m\u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mmse_loss(s_feat_resized, t_feat)\n\u001b[1;32m    143\u001b[0m \u001b[38;5;66;03m# Classification Loss 계산\u001b[39;00m\n\u001b[0;32m--> 144\u001b[0m student_output_resized \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43moutput_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mstudent_output\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    145\u001b[0m classification_loss \u001b[38;5;241m=\u001b[39m F\u001b[38;5;241m.\u001b[39mcross_entropy(student_output_resized, labels) \u001b[38;5;28;01mif\u001b[39;00m labels \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;241m0.0\u001b[39m\n\u001b[1;32m    147\u001b[0m \u001b[38;5;66;03m# Total Loss 계산\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1510\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1508\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1509\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1510\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/module.py:1519\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1514\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1515\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1516\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1517\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1518\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1519\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1521\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1522\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m/usr/local/lib/python3.10/dist-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlinear\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mbias\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: mat1 and mat2 shapes cannot be multiplied (1x5 and 768x5)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 5\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# Create distillation model\n",
    "model = create_model(model_name, teacher_model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "model.to('cpu')\n",
    "\n",
    "# Generate random input (batch size = 1, 3 channels, 224x224 image)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# Pass the input through the model\n",
    "student_output_resized, teacher_output, distillation_loss = model(random_input)\n",
    "\n",
    "# Check the shape of the output and distillation loss\n",
    "print(\"Student Output shape:\", student_output_resized.shape)\n",
    "print(\"Teacher Output shape:\", teacher_output.shape)\n",
    "print(f\"Distillation loss: {distillation_loss}\")\n",
    "\n",
    "# Print the feature maps from intermediate layers\n",
    "for i, (transform, student_feature, teacher_feature) in enumerate(zip(model.transforms, model.student_model.features, model.teacher_model.features)):\n",
    "    print(f\"Student Feature {i+1} original shape:\", student_feature.shape)\n",
    "    transformed_feature = transform(student_feature.permute(0, 3, 1, 2))\n",
    "    print(f\"Student Feature {i+1} transformed shape:\", transformed_feature.shape)\n",
    "    print(f\"Teacher Feature {i+1} shape:\", teacher_feature.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "--- Teacher Model Feature Shapes ---\n",
      "Teacher Layer 1: torch.Size([1, 256, 56, 56])\n",
      "Teacher Layer 2: torch.Size([1, 512, 28, 28])\n",
      "Teacher Layer 3: torch.Size([1, 1024, 14, 14])\n",
      "\n",
      "--- Student Model Feature Shapes ---\n",
      "Student Layer 1: torch.Size([1, 56, 56, 96])\n",
      "Student Layer 2: torch.Size([1, 28, 28, 192])\n",
      "Student Layer 3: torch.Size([1, 14, 14, 384])\n",
      "Student Layer 4: torch.Size([1, 7, 7, 768])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model 설정\n",
    "student_model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# Distillation model 생성\n",
    "model = create_model(student_model_name, teacher_model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "model.to('cpu')\n",
    "\n",
    "# 임의의 입력 데이터 생성 (batch size = 1, 3 channels, 224x224 image)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# forward pass를 통해 레이어별 feature shape 확인\n",
    "with torch.no_grad():\n",
    "    _, _, _ = model(random_input)\n",
    "\n",
    "# 각 레이어의 feature shape 출력\n",
    "print(\"\\n--- Teacher Model Feature Shapes ---\")\n",
    "for i, feat in enumerate(model.teacher_model.features):\n",
    "    print(f\"Teacher Layer {i+1}: {feat.shape}\")\n",
    "\n",
    "print(\"\\n--- Student Model Feature Shapes ---\")\n",
    "for i, feat in enumerate(model.student_model.features):\n",
    "    print(f\"Student Layer {i+1}: {feat.shape}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "too many values to unpack (expected 3)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[44], line 23\u001b[0m\n\u001b[1;32m     21\u001b[0m \u001b[38;5;66;03m# forward pass를 통해 레이어별 feature shape 확인\u001b[39;00m\n\u001b[1;32m     22\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m torch\u001b[38;5;241m.\u001b[39mno_grad():\n\u001b[0;32m---> 23\u001b[0m     student_output_resized, teacher_output, _ \u001b[38;5;241m=\u001b[39m model(random_input)\n\u001b[1;32m     25\u001b[0m \u001b[38;5;66;03m# 각 레이어의 feature shape 출력\u001b[39;00m\n\u001b[1;32m     26\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m--- Teacher Model Feature Shapes ---\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "\u001b[0;31mValueError\u001b[0m: too many values to unpack (expected 3)"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# Model 설정\n",
    "student_model_name = 'swin_tiny_patch4_window7_224'\n",
    "teacher_model_name = 'resnet50'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "beta = 1.0\n",
    "\n",
    "# Distillation model 생성\n",
    "teacher_model = TeacherModel(model_name=teacher_model_name, pretrained=pretrained, num_classes=num_classes)\n",
    "student_model = StudentModel(model_name=student_model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "model = DistillationModel(teacher_model, student_model, beta=beta)\n",
    "model.to('cpu')\n",
    "\n",
    "# 임의의 입력 데이터 생성 (batch size = 1, 3 channels, 224x224 image)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# forward pass를 통해 레이어별 feature shape 확인\n",
    "with torch.no_grad():\n",
    "    student_output_resized, teacher_output, _ = model(random_input)\n",
    "\n",
    "# 각 레이어의 feature shape 출력\n",
    "print(\"\\n--- Teacher Model Feature Shapes ---\")\n",
    "for i, feat in enumerate(model.teacher_model.features):\n",
    "    print(f\"Teacher Layer {i+1}: {feat.shape}\")\n",
    "\n",
    "print(\"\\n--- Student Model Feature Shapes (Before Transformation) ---\")\n",
    "for i, feat in enumerate(model.student_model.features):\n",
    "    print(f\"Student Layer {i+1}: {feat.shape}\")\n",
    "\n",
    "# 변환 후 feature shape 확인\n",
    "print(\"\\n--- Transformed Student Feature Shapes (After Alignment) ---\")\n",
    "for i, (transform, s_feat, t_feat) in enumerate(zip(model.transforms, model.student_model.features[:-1], model.teacher_model.features)):\n",
    "    # 채널 변환 및 공간 정렬 수행\n",
    "    transformed_feat = F.interpolate(transform(s_feat), size=(t_feat.shape[2], t_feat.shape[3]), mode='bilinear')\n",
    "    print(f\"Transformed Student Layer {i+1}: {transformed_feat.shape} (aligned to Teacher Layer {i+1})\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "from functools import partial\n",
    "from itertools import repeat\n",
    "import collections.abc as container_abcs\n",
    "\n",
    "import logging\n",
    "import os\n",
    "from collections import OrderedDict\n",
    "\n",
    "import numpy as np\n",
    "import scipy\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from einops import rearrange\n",
    "from einops.layers.torch import Rearrange\n",
    "\n",
    "from timm.models.layers import DropPath, trunc_normal_\n",
    "\n",
    "#from .registry import register_model\n",
    "\n",
    "\n",
    "# From PyTorch internals\n",
    "def _ntuple(n):\n",
    "    def parse(x):\n",
    "        if isinstance(x, container_abcs.Iterable):\n",
    "            return x\n",
    "        return tuple(repeat(x, n))\n",
    "\n",
    "    return parse\n",
    "\n",
    "\n",
    "to_1tuple = _ntuple(1)\n",
    "to_2tuple = _ntuple(2)\n",
    "to_3tuple = _ntuple(3)\n",
    "to_4tuple = _ntuple(4)\n",
    "to_ntuple = _ntuple\n",
    "\n",
    "\n",
    "class LayerNorm(nn.LayerNorm):\n",
    "    \"\"\"Subclass torch's LayerNorm to handle fp16.\"\"\"\n",
    "\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        orig_type = x.dtype\n",
    "        ret = super().forward(x.type(torch.float32))\n",
    "        return ret.type(orig_type)\n",
    "\n",
    "\n",
    "class QuickGELU(nn.Module):\n",
    "    def forward(self, x: torch.Tensor):\n",
    "        return x * torch.sigmoid(1.702 * x)\n",
    "\n",
    "\n",
    "class Mlp(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_features,\n",
    "                 hidden_features=None,\n",
    "                 out_features=None,\n",
    "                 act_layer=nn.GELU,\n",
    "                 drop=0.):\n",
    "        super().__init__()\n",
    "        out_features = out_features or in_features\n",
    "        hidden_features = hidden_features or in_features\n",
    "        self.fc1 = nn.Linear(in_features, hidden_features)\n",
    "        self.act = act_layer()\n",
    "        self.fc2 = nn.Linear(hidden_features, out_features)\n",
    "        self.drop = nn.Dropout(drop)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.fc1(x)\n",
    "        x = self.act(x)\n",
    "        x = self.drop(x)\n",
    "        x = self.fc2(x)\n",
    "        x = self.drop(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "class Attention(nn.Module):\n",
    "    def __init__(self,\n",
    "                 dim_in,\n",
    "                 dim_out,\n",
    "                 num_heads,\n",
    "                 qkv_bias=False,\n",
    "                 attn_drop=0.,\n",
    "                 proj_drop=0.,\n",
    "                 method='dw_bn',\n",
    "                 kernel_size=3,\n",
    "                 stride_kv=1,\n",
    "                 stride_q=1,\n",
    "                 padding_kv=1,\n",
    "                 padding_q=1,\n",
    "                 with_cls_token=True,\n",
    "                 **kwargs\n",
    "                 ):\n",
    "        super().__init__()\n",
    "        self.stride_kv = stride_kv\n",
    "        self.stride_q = stride_q\n",
    "        self.dim = dim_out\n",
    "        self.num_heads = num_heads\n",
    "        # head_dim = self.qkv_dim // num_heads\n",
    "        self.scale = dim_out ** -0.5\n",
    "        self.with_cls_token = with_cls_token\n",
    "\n",
    "        self.conv_proj_q = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_q,\n",
    "            stride_q, 'linear' if method == 'avg' else method\n",
    "        )\n",
    "        self.conv_proj_k = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_kv,\n",
    "            stride_kv, method\n",
    "        )\n",
    "        self.conv_proj_v = self._build_projection(\n",
    "            dim_in, dim_out, kernel_size, padding_kv,\n",
    "            stride_kv, method\n",
    "        )\n",
    "\n",
    "        self.proj_q = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.proj_k = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "        self.proj_v = nn.Linear(dim_in, dim_out, bias=qkv_bias)\n",
    "\n",
    "        self.attn_drop = nn.Dropout(attn_drop)\n",
    "        self.proj = nn.Linear(dim_out, dim_out)\n",
    "        self.proj_drop = nn.Dropout(proj_drop)\n",
    "\n",
    "    def _build_projection(self,\n",
    "                          dim_in,\n",
    "                          dim_out,\n",
    "                          kernel_size,\n",
    "                          padding,\n",
    "                          stride,\n",
    "                          method):\n",
    "        if method == 'dw_bn':\n",
    "            proj = nn.Sequential(OrderedDict([\n",
    "                ('conv', nn.Conv2d(\n",
    "                    dim_in,\n",
    "                    dim_in,\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    bias=False,\n",
    "                    groups=dim_in\n",
    "                )),\n",
    "                ('bn', nn.BatchNorm2d(dim_in)),\n",
    "                ('rearrage', Rearrange('b c h w -> b (h w) c')),\n",
    "            ]))\n",
    "        elif method == 'avg':\n",
    "            proj = nn.Sequential(OrderedDict([\n",
    "                ('avg', nn.AvgPool2d(\n",
    "                    kernel_size=kernel_size,\n",
    "                    padding=padding,\n",
    "                    stride=stride,\n",
    "                    ceil_mode=True\n",
    "                )),\n",
    "                ('rearrage', Rearrange('b c h w -> b (h w) c')),\n",
    "            ]))\n",
    "        elif method == 'linear':\n",
    "            proj = None\n",
    "        else:\n",
    "            raise ValueError('Unknown method ({})'.format(method))\n",
    "\n",
    "        return proj\n",
    "\n",
    "    def forward_conv(self, x, h, w):\n",
    "        if self.with_cls_token:\n",
    "            cls_token, x = torch.split(x, [1, h*w], 1)\n",
    "\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=h, w=w)\n",
    "\n",
    "        if self.conv_proj_q is not None:\n",
    "            q = self.conv_proj_q(x)\n",
    "        else:\n",
    "            q = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.conv_proj_k is not None:\n",
    "            k = self.conv_proj_k(x)\n",
    "        else:\n",
    "            k = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.conv_proj_v is not None:\n",
    "            v = self.conv_proj_v(x)\n",
    "        else:\n",
    "            v = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        if self.with_cls_token:\n",
    "            q = torch.cat((cls_token, q), dim=1)\n",
    "            k = torch.cat((cls_token, k), dim=1)\n",
    "            v = torch.cat((cls_token, v), dim=1)\n",
    "\n",
    "        return q, k, v\n",
    "\n",
    "    def forward(self, x, h, w):\n",
    "        if (\n",
    "            self.conv_proj_q is not None\n",
    "            or self.conv_proj_k is not None\n",
    "            or self.conv_proj_v is not None\n",
    "        ):\n",
    "            q, k, v = self.forward_conv(x, h, w)\n",
    "\n",
    "        q = rearrange(self.proj_q(q), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        k = rearrange(self.proj_k(k), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "        v = rearrange(self.proj_v(v), 'b t (h d) -> b h t d', h=self.num_heads)\n",
    "\n",
    "        attn_score = torch.einsum('bhlk,bhtk->bhlt', [q, k]) * self.scale\n",
    "        attn = F.softmax(attn_score, dim=-1)\n",
    "        attn = self.attn_drop(attn)\n",
    "\n",
    "        x = torch.einsum('bhlt,bhtv->bhlv', [attn, v])\n",
    "        x = rearrange(x, 'b h t d -> b t (h d)')\n",
    "\n",
    "        x = self.proj(x)\n",
    "        x = self.proj_drop(x)\n",
    "\n",
    "        return x\n",
    "\n",
    "    @staticmethod\n",
    "    def compute_macs(module, input, output):\n",
    "        # T: num_token\n",
    "        # S: num_token\n",
    "        input = input[0]\n",
    "        flops = 0\n",
    "\n",
    "        _, T, C = input.shape\n",
    "        H = W = int(np.sqrt(T-1)) if module.with_cls_token else int(np.sqrt(T))\n",
    "\n",
    "        H_Q = H / module.stride_q\n",
    "        W_Q = H / module.stride_q\n",
    "        T_Q = H_Q * W_Q + 1 if module.with_cls_token else H_Q * W_Q\n",
    "\n",
    "        H_KV = H / module.stride_kv\n",
    "        W_KV = W / module.stride_kv\n",
    "        T_KV = H_KV * W_KV + 1 if module.with_cls_token else H_KV * W_KV\n",
    "\n",
    "        # C = module.dim\n",
    "        # S = T\n",
    "        # Scaled-dot-product macs\n",
    "        # [B x T x C] x [B x C x T] --> [B x T x S]\n",
    "        # multiplication-addition is counted as 1 because operations can be fused\n",
    "        flops += T_Q * T_KV * module.dim\n",
    "        # [B x T x S] x [B x S x C] --> [B x T x C]\n",
    "        flops += T_Q * module.dim * T_KV\n",
    "\n",
    "        if (\n",
    "            hasattr(module, 'conv_proj_q')\n",
    "            and hasattr(module.conv_proj_q, 'conv')\n",
    "        ):\n",
    "            params = sum(\n",
    "                [\n",
    "                    p.numel()\n",
    "                    for p in module.conv_proj_q.conv.parameters()\n",
    "                ]\n",
    "            )\n",
    "            flops += params * H_Q * W_Q\n",
    "\n",
    "        if (\n",
    "            hasattr(module, 'conv_proj_k')\n",
    "            and hasattr(module.conv_proj_k, 'conv')\n",
    "        ):\n",
    "            params = sum(\n",
    "                [\n",
    "                    p.numel()\n",
    "                    for p in module.conv_proj_k.conv.parameters()\n",
    "                ]\n",
    "            )\n",
    "            flops += params * H_KV * W_KV\n",
    "\n",
    "        if (\n",
    "            hasattr(module, 'conv_proj_v')\n",
    "            and hasattr(module.conv_proj_v, 'conv')\n",
    "        ):\n",
    "            params = sum(\n",
    "                [\n",
    "                    p.numel()\n",
    "                    for p in module.conv_proj_v.conv.parameters()\n",
    "                ]\n",
    "            )\n",
    "            flops += params * H_KV * W_KV\n",
    "\n",
    "        params = sum([p.numel() for p in module.proj_q.parameters()])\n",
    "        flops += params * T_Q\n",
    "        params = sum([p.numel() for p in module.proj_k.parameters()])\n",
    "        flops += params * T_KV\n",
    "        params = sum([p.numel() for p in module.proj_v.parameters()])\n",
    "        flops += params * T_KV\n",
    "        params = sum([p.numel() for p in module.proj.parameters()])\n",
    "        flops += params * T\n",
    "\n",
    "        module.__flops__ += flops\n",
    "\n",
    "\n",
    "class Block(nn.Module):\n",
    "\n",
    "    def __init__(self,\n",
    "                 dim_in,\n",
    "                 dim_out,\n",
    "                 num_heads,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop=0.,\n",
    "                 attn_drop=0.,\n",
    "                 drop_path=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "\n",
    "        self.with_cls_token = kwargs['with_cls_token']\n",
    "\n",
    "        self.norm1 = norm_layer(dim_in)\n",
    "        self.attn = Attention(\n",
    "            dim_in, dim_out, num_heads, qkv_bias, attn_drop, drop,\n",
    "            **kwargs\n",
    "        )\n",
    "\n",
    "        self.drop_path = DropPath(drop_path) \\\n",
    "            if drop_path > 0. else nn.Identity()\n",
    "        self.norm2 = norm_layer(dim_out)\n",
    "\n",
    "        dim_mlp_hidden = int(dim_out * mlp_ratio)\n",
    "        self.mlp = Mlp(\n",
    "            in_features=dim_out,\n",
    "            hidden_features=dim_mlp_hidden,\n",
    "            act_layer=act_layer,\n",
    "            drop=drop\n",
    "        )\n",
    "\n",
    "    def forward(self, x, h, w):\n",
    "        res = x\n",
    "\n",
    "        x = self.norm1(x)\n",
    "        attn = self.attn(x, h, w)\n",
    "        x = res + self.drop_path(attn)\n",
    "        x = x + self.drop_path(self.mlp(self.norm2(x)))\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class ConvEmbed(nn.Module):\n",
    "    \"\"\" Image to Conv Embedding\n",
    "\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self,\n",
    "                 patch_size=7,\n",
    "                 in_chans=3,\n",
    "                 embed_dim=64,\n",
    "                 stride=4,\n",
    "                 padding=2,\n",
    "                 norm_layer=None):\n",
    "        super().__init__()\n",
    "        patch_size = to_2tuple(patch_size)\n",
    "        self.patch_size = patch_size\n",
    "\n",
    "        self.proj = nn.Conv2d(\n",
    "            in_chans, embed_dim,\n",
    "            kernel_size=patch_size,\n",
    "            stride=stride,\n",
    "            padding=padding\n",
    "        )\n",
    "        self.norm = norm_layer(embed_dim) if norm_layer else None\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.proj(x)\n",
    "\n",
    "        B, C, H, W = x.shape\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "        if self.norm:\n",
    "            x = self.norm(x)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=H, w=W)\n",
    "\n",
    "        return x\n",
    "\n",
    "\n",
    "class VisionTransformer(nn.Module):\n",
    "    \"\"\" Vision Transformer with support for patch or hybrid CNN input stage\n",
    "    \"\"\"\n",
    "    def __init__(self,\n",
    "                 patch_size=16,\n",
    "                 patch_stride=16,\n",
    "                 patch_padding=0,\n",
    "                 in_chans=3,\n",
    "                 embed_dim=768,\n",
    "                 depth=12,\n",
    "                 num_heads=12,\n",
    "                 mlp_ratio=4.,\n",
    "                 qkv_bias=False,\n",
    "                 drop_rate=0.,\n",
    "                 attn_drop_rate=0.,\n",
    "                 drop_path_rate=0.,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 **kwargs):\n",
    "        super().__init__()\n",
    "        self.num_features = self.embed_dim = embed_dim  # num_features for consistency with other models\n",
    "\n",
    "        self.rearrage = None\n",
    "\n",
    "        self.patch_embed = ConvEmbed(\n",
    "            # img_size=img_size,\n",
    "            patch_size=patch_size,\n",
    "            in_chans=in_chans,\n",
    "            stride=patch_stride,\n",
    "            padding=patch_padding,\n",
    "            embed_dim=embed_dim,\n",
    "            norm_layer=norm_layer\n",
    "        )\n",
    "\n",
    "        with_cls_token = kwargs['with_cls_token']\n",
    "        if with_cls_token:\n",
    "            self.cls_token = nn.Parameter(\n",
    "                torch.zeros(1, 1, embed_dim)\n",
    "            )\n",
    "        else:\n",
    "            self.cls_token = None\n",
    "\n",
    "        self.pos_drop = nn.Dropout(p=drop_rate)\n",
    "        dpr = [x.item() for x in torch.linspace(0, drop_path_rate, depth)]  # stochastic depth decay rule\n",
    "\n",
    "        blocks = []\n",
    "        for j in range(depth):\n",
    "            blocks.append(\n",
    "                Block(\n",
    "                    dim_in=embed_dim,\n",
    "                    dim_out=embed_dim,\n",
    "                    num_heads=num_heads,\n",
    "                    mlp_ratio=mlp_ratio,\n",
    "                    qkv_bias=qkv_bias,\n",
    "                    drop=drop_rate,\n",
    "                    attn_drop=attn_drop_rate,\n",
    "                    drop_path=dpr[j],\n",
    "                    act_layer=act_layer,\n",
    "                    norm_layer=norm_layer,\n",
    "                    **kwargs\n",
    "                )\n",
    "            )\n",
    "        self.blocks = nn.ModuleList(blocks)\n",
    "\n",
    "        if self.cls_token is not None:\n",
    "            trunc_normal_(self.cls_token, std=.02)\n",
    "\n",
    "        if init == 'xavier':\n",
    "            self.apply(self._init_weights_xavier)\n",
    "        else:\n",
    "            self.apply(self._init_weights_trunc_normal)\n",
    "\n",
    "    def _init_weights_trunc_normal(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            logging.info('=> init weight of Linear from trunc norm')\n",
    "            trunc_normal_(m.weight, std=0.02)\n",
    "            if m.bias is not None:\n",
    "                logging.info('=> init bias of Linear to zeros')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def _init_weights_xavier(self, m):\n",
    "        if isinstance(m, nn.Linear):\n",
    "            logging.info('=> init weight of Linear from xavier uniform')\n",
    "            nn.init.xavier_uniform_(m.weight)\n",
    "            if m.bias is not None:\n",
    "                logging.info('=> init bias of Linear to zeros')\n",
    "                nn.init.constant_(m.bias, 0)\n",
    "        elif isinstance(m, (nn.LayerNorm, nn.BatchNorm2d)):\n",
    "            nn.init.constant_(m.bias, 0)\n",
    "            nn.init.constant_(m.weight, 1.0)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.patch_embed(x)\n",
    "        B, C, H, W = x.size()\n",
    "\n",
    "        x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "\n",
    "        cls_tokens = None\n",
    "        if self.cls_token is not None:\n",
    "            # stole cls_tokens impl from Phil Wang, thanks\n",
    "            cls_tokens = self.cls_token.expand(B, -1, -1)\n",
    "            x = torch.cat((cls_tokens, x), dim=1)\n",
    "\n",
    "        x = self.pos_drop(x)\n",
    "\n",
    "        for i, blk in enumerate(self.blocks):\n",
    "            x = blk(x, H, W)\n",
    "\n",
    "        if self.cls_token is not None:\n",
    "            cls_tokens, x = torch.split(x, [1, H*W], 1)\n",
    "        x = rearrange(x, 'b (h w) c -> b c h w', h=H, w=W)\n",
    "\n",
    "        return x, cls_tokens\n",
    "\n",
    "\n",
    "class ConvolutionalVisionTransformer(nn.Module):\n",
    "    def __init__(self,\n",
    "                 in_chans=3,\n",
    "                 num_classes=1000,\n",
    "                 act_layer=nn.GELU,\n",
    "                 norm_layer=nn.LayerNorm,\n",
    "                 init='trunc_norm',\n",
    "                 spec=None):\n",
    "        super().__init__()\n",
    "        self.num_classes = num_classes\n",
    "\n",
    "        self.num_stages = spec['NUM_STAGES']\n",
    "        for i in range(self.num_stages):\n",
    "            kwargs = {\n",
    "                'patch_size': spec['PATCH_SIZE'][i],\n",
    "                'patch_stride': spec['PATCH_STRIDE'][i],\n",
    "                'patch_padding': spec['PATCH_PADDING'][i],\n",
    "                'embed_dim': spec['DIM_EMBED'][i],\n",
    "                'depth': spec['DEPTH'][i],\n",
    "                'num_heads': spec['NUM_HEADS'][i],\n",
    "                'mlp_ratio': spec['MLP_RATIO'][i],\n",
    "                'qkv_bias': spec['QKV_BIAS'][i],\n",
    "                'drop_rate': spec['DROP_RATE'][i],\n",
    "                'attn_drop_rate': spec['ATTN_DROP_RATE'][i],\n",
    "                'drop_path_rate': spec['DROP_PATH_RATE'][i],\n",
    "                'with_cls_token': spec['CLS_TOKEN'][i],\n",
    "                'method': spec['QKV_PROJ_METHOD'][i],\n",
    "                'kernel_size': spec['KERNEL_QKV'][i],\n",
    "                'padding_q': spec['PADDING_Q'][i],\n",
    "                'padding_kv': spec['PADDING_KV'][i],\n",
    "                'stride_kv': spec['STRIDE_KV'][i],\n",
    "                'stride_q': spec['STRIDE_Q'][i],\n",
    "            }\n",
    "\n",
    "            stage = VisionTransformer(\n",
    "                in_chans=in_chans,\n",
    "                init=init,\n",
    "                act_layer=act_layer,\n",
    "                norm_layer=norm_layer,\n",
    "                **kwargs\n",
    "            )\n",
    "            setattr(self, f'stage{i}', stage)\n",
    "\n",
    "            in_chans = spec['DIM_EMBED'][i]\n",
    "\n",
    "        dim_embed = spec['DIM_EMBED'][-1]\n",
    "        self.norm = norm_layer(dim_embed)\n",
    "        self.num_features = dim_embed\n",
    "        self.cls_token = spec['CLS_TOKEN'][-1]\n",
    "\n",
    "        # Classifier head\n",
    "        self.head = nn.Linear(dim_embed, num_classes) if num_classes > 0 else nn.Identity()\n",
    "        trunc_normal_(self.head.weight, std=0.02)\n",
    "\n",
    "    def init_weights(self, pretrained='', pretrained_layers=[], verbose=True):\n",
    "        if os.path.isfile(pretrained):\n",
    "            pretrained_dict = torch.load(pretrained, map_location='cpu')\n",
    "            logging.info(f'=> loading pretrained model {pretrained}')\n",
    "            model_dict = self.state_dict()\n",
    "            pretrained_dict = {\n",
    "                k: v for k, v in pretrained_dict.items()\n",
    "                if k in model_dict.keys()\n",
    "            }\n",
    "            need_init_state_dict = {}\n",
    "            for k, v in pretrained_dict.items():\n",
    "                need_init = (\n",
    "                        k.split('.')[0] in pretrained_layers\n",
    "                        or pretrained_layers[0] == '*'\n",
    "                )\n",
    "                if need_init:\n",
    "                    if verbose:\n",
    "                        logging.info(f'=> init {k} from {pretrained}')\n",
    "                    if 'pos_embed' in k and v.size() != model_dict[k].size():\n",
    "                        size_pretrained = v.size()\n",
    "                        size_new = model_dict[k].size()\n",
    "                        logging.info(\n",
    "                            '=> load_pretrained: resized variant: {} to {}'\n",
    "                            .format(size_pretrained, size_new)\n",
    "                        )\n",
    "\n",
    "                        ntok_new = size_new[1]\n",
    "                        ntok_new -= 1\n",
    "\n",
    "                        posemb_tok, posemb_grid = v[:, :1], v[0, 1:]\n",
    "\n",
    "                        gs_old = int(np.sqrt(len(posemb_grid)))\n",
    "                        gs_new = int(np.sqrt(ntok_new))\n",
    "\n",
    "                        logging.info(\n",
    "                            '=> load_pretrained: grid-size from {} to {}'\n",
    "                            .format(gs_old, gs_new)\n",
    "                        )\n",
    "\n",
    "                        posemb_grid = posemb_grid.reshape(gs_old, gs_old, -1)\n",
    "                        zoom = (gs_new / gs_old, gs_new / gs_old, 1)\n",
    "                        posemb_grid = scipy.ndimage.zoom(\n",
    "                            posemb_grid, zoom, order=1\n",
    "                        )\n",
    "                        posemb_grid = posemb_grid.reshape(1, gs_new ** 2, -1)\n",
    "                        v = torch.tensor(\n",
    "                            np.concatenate([posemb_tok, posemb_grid], axis=1)\n",
    "                        )\n",
    "\n",
    "                    need_init_state_dict[k] = v\n",
    "            self.load_state_dict(need_init_state_dict, strict=False)\n",
    "\n",
    "    @torch.jit.ignore\n",
    "    def no_weight_decay(self):\n",
    "        layers = set()\n",
    "        for i in range(self.num_stages):\n",
    "            layers.add(f'stage{i}.pos_embed')\n",
    "            layers.add(f'stage{i}.cls_token')\n",
    "\n",
    "        return layers\n",
    "\n",
    "    def forward_features(self, x):\n",
    "        for i in range(self.num_stages):\n",
    "            x, cls_tokens = getattr(self, f'stage{i}')(x)\n",
    "\n",
    "        if self.cls_token:\n",
    "            x = self.norm(cls_tokens)\n",
    "            x = torch.squeeze(x)\n",
    "        else:\n",
    "            x = rearrange(x, 'b c h w -> b (h w) c')\n",
    "            x = self.norm(x)\n",
    "            x = torch.mean(x, dim=1)\n",
    "\n",
    "        return x\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.forward_features(x)\n",
    "        x = self.head(x)\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Output shape: torch.Size([1000])\n",
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 384, 14, 14]) torch.Size([1, 1, 384])\n",
      "after avg pool: torch.Size([1, 384, 7, 7])\n",
      "torch.Size([1, 384])\n",
      "torch.Size([1, 384])\n",
      "Output shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "from functools import partial\n",
    "from collections import namedtuple\n",
    "\n",
    "# Provided CvT model definition imports\n",
    "# Assume that ConvolutionalVisionTransformer and LayerNorm are defined as per the code you provided\n",
    "\n",
    "# Create a configuration for the CvT model\n",
    "Config = namedtuple('Config', ['MODEL', 'VERBOSE'])\n",
    "ModelConfig = namedtuple('ModelConfig', ['SPEC', 'NUM_CLASSES', 'PRETRAINED', 'PRETRAINED_LAYERS', 'INIT_WEIGHTS'])\n",
    "SpecConfig = namedtuple('SpecConfig', [\n",
    "    'NUM_STAGES', 'PATCH_SIZE', 'PATCH_STRIDE', 'PATCH_PADDING', 'DIM_EMBED', 'DEPTH',\n",
    "    'NUM_HEADS', 'MLP_RATIO', 'QKV_BIAS', 'DROP_RATE', 'ATTN_DROP_RATE', 'DROP_PATH_RATE',\n",
    "    'CLS_TOKEN', 'QKV_PROJ_METHOD', 'KERNEL_QKV', 'PADDING_Q', 'PADDING_KV', 'STRIDE_KV', 'STRIDE_Q'\n",
    "])\n",
    "\n",
    "# Define the model specifications\n",
    "spec = SpecConfig(\n",
    "    NUM_STAGES=3,\n",
    "    PATCH_SIZE=[7, 3, 3],\n",
    "    PATCH_STRIDE=[4, 2, 2],\n",
    "    PATCH_PADDING=[2, 1, 1],\n",
    "    DIM_EMBED=[64, 192, 384],\n",
    "    DEPTH=[1, 2, 10],\n",
    "    NUM_HEADS=[1, 3, 6],\n",
    "    MLP_RATIO=[4.0, 4.0, 4.0],\n",
    "    QKV_BIAS=[True, True, True],\n",
    "    DROP_RATE=[0.0, 0.0, 0.0],\n",
    "    ATTN_DROP_RATE=[0.0, 0.0, 0.0],\n",
    "    DROP_PATH_RATE=[0.0, 0.1, 0.2],\n",
    "    CLS_TOKEN=[False, False, True],\n",
    "    QKV_PROJ_METHOD=['dw_bn', 'dw_bn', 'dw_bn'],\n",
    "    KERNEL_QKV=[3, 3, 3],\n",
    "    PADDING_Q=[1, 1, 1],\n",
    "    PADDING_KV=[1, 1, 1],\n",
    "    STRIDE_KV=[2, 2, 2],\n",
    "    STRIDE_Q=[1, 1, 1]\n",
    ")\n",
    "\n",
    "# Define the model configuration\n",
    "model_config = ModelConfig(\n",
    "    SPEC=spec,\n",
    "    NUM_CLASSES=1000,\n",
    "    PRETRAINED='',\n",
    "    PRETRAINED_LAYERS=['*'],\n",
    "    INIT_WEIGHTS=True\n",
    ")\n",
    "\n",
    "# Create the full configuration\n",
    "config = Config(\n",
    "    MODEL=model_config,\n",
    "    VERBOSE=True\n",
    ")\n",
    "\n",
    "# Instantiate the CvT model\n",
    "cvt_model = ConvolutionalVisionTransformer(\n",
    "    in_chans=3,\n",
    "    num_classes=config.MODEL.NUM_CLASSES,\n",
    "    act_layer=QuickGELU,\n",
    "    norm_layer=partial(LayerNorm, eps=1e-5),\n",
    "    init='trunc_norm',\n",
    "    spec=config.MODEL.SPEC._asdict()\n",
    ")\n",
    "\n",
    "# Initialize model weights if required\n",
    "if config.MODEL.INIT_WEIGHTS:\n",
    "    cvt_model.init_weights(\n",
    "        config.MODEL.PRETRAINED,\n",
    "        config.MODEL.PRETRAINED_LAYERS,\n",
    "        config.VERBOSE\n",
    "    )\n",
    "\n",
    "# Create a random input tensor with the shape (batch_size, channels, height, width)\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "cvt_model.eval()\n",
    "\n",
    "# Perform a forward pass\n",
    "with torch.no_grad():\n",
    "    output = cvt_model(input_tensor)\n",
    "\n",
    "# Print the output shape (should be [batch_size, num_classes])\n",
    "print(\"Output shape:\", output.shape) \n",
    "\n",
    "class CvtModel(nn.Module):\n",
    "    def __init__(self, cvt_model):\n",
    "        super(CvtModel, self).__init__()\n",
    "        self.base_model = cvt_model\n",
    "\n",
    "        self.base_model.head = nn.Identity()\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        print(x.shape)\n",
    "        \n",
    "        x, _ = self.base_model.stage0(x)\n",
    "        #print(x.shape, cls_tokens)\n",
    "        \n",
    "        x, _ = self.base_model.stage1(x)\n",
    "        #print(x.shape, cls_tokens)\n",
    "        \n",
    "        x, cls_tokens = self.base_model.stage2(x)\n",
    "        print(x.shape, cls_tokens.shape)\n",
    "        \n",
    "        x = self.avg_pool(x) # 14x14에서 7x7로 다운샘플링\n",
    "        print(\"after avg pool:\", x.shape)\n",
    "        \n",
    "        cls_tokens = self.base_model.norm(cls_tokens)\n",
    "        cls_tokens = torch.squeeze(cls_tokens, dim=1)\n",
    "        print(cls_tokens.shape)\n",
    "        \n",
    "        return cls_tokens\n",
    "\n",
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.num_features = self.base_model.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        \n",
    "        print(base_output.shape)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "model = CvtModel(cvt_model)\n",
    "model = MLP_layer(model, 5)\n",
    "\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Print the output shape (should be [batch_size, num_classes])\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "adopt performer encoder for tokens-to-token\n",
      "torch.Size([1, 196, 384])\n",
      "After adding cls_token: torch.Size([1, 197, 384])\n",
      "torch.Size([1, 197, 384])\n",
      "torch.Size([1, 197, 384])\n",
      "cls_token: torch.Size([1, 384])\n",
      "patch_token: torch.Size([1, 384, 7, 7])\n",
      "Output shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import sys\n",
    "import os\n",
    "\n",
    "# sys.path.append('/home/work/')\n",
    "# print(sys.path)\n",
    "\n",
    "\n",
    "from T2T_ViT.T2T_ViT_main.models.t2t_vit import t2t_vit_14\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = t2t_vit_14()\n",
    "        self.base_model.head = nn.Identity()\n",
    "        \n",
    "        self.avg_pool = nn.AvgPool2d(kernel_size=2, stride=2)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        B = x.shape[0]\n",
    "        \n",
    "        x = self.base_model.tokens_to_token(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        cls_tokens = self.base_model.cls_token.expand(B, -1, -1)\n",
    "        x = torch.cat((cls_tokens, x), dim=1)\n",
    "        print(\"After adding cls_token:\", x.shape)\n",
    "        \n",
    "        x = x + self.base_model.pos_embed\n",
    "        x = self.base_model.pos_drop(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        for i, block in enumerate(self.base_model.blocks) :\n",
    "            x = block(x)\n",
    "        \n",
    "        x = self.base_model.norm(x)\n",
    "        print(x.shape)\n",
    "        \n",
    "        cls_token = x[:, 0]\n",
    "        print(\"cls_token:\", cls_token.shape)\n",
    "        \n",
    "        patch_token = x[:, 1:] # (batch_size, 196, 768)\n",
    "        batch_size, num_patches, embed_dim = patch_token.shape\n",
    "        patch_token = patch_token.view(batch_size, 14, 14, embed_dim) # n, k, k, d\n",
    "        patch_token = patch_token.permute(0, 3, 1, 2) # n, d, k, k\n",
    "        patch_token = self.avg_pool(patch_token) # n, d, 14, 14 -> n, d, 7, 7\n",
    "        \n",
    "        print(\"patch_token:\", patch_token.shape)\n",
    "        \n",
    "        \n",
    "        return cls_token\n",
    "\n",
    "    \n",
    "\n",
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.num_features = self.base_model.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "def create_model(model_name, pretrained, num_classes, in_chans, out_dim):\n",
    "\n",
    "    if out_dim <= 0:\n",
    "        raise ValueError(\"오류: out_dim이 0 이하입니다.\")\n",
    "\n",
    "    base_model = BaseModel(model_name, pretrained, num_classes, in_chans)\n",
    "    model = MLP_layer(base_model, out_dim)\n",
    "\n",
    "    return model\n",
    "\n",
    "\n",
    "model = create_model('', False, 0, 3, 5)\n",
    "\n",
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "model.eval()\n",
    "\n",
    "# Perform a forward pass\n",
    "with torch.no_grad():\n",
    "    output = model(input_tensor)\n",
    "\n",
    "# Print the output shape (should be [batch_size, num_classes])\n",
    "print(\"Output shape:\", output.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import mlflow\n",
    "import mlflow.pyfunc\n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.base_model(x)\n",
    "        return x\n",
    "\n",
    "    \n",
    "\n",
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        # Freeze base_model\n",
    "        for param in self.base_model.parameters():\n",
    "            param.requires_grad = False\n",
    "\n",
    "        self.num_features = self.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)\n",
    "\n",
    "def create_model(model_name, pretrained, num_classes, in_chans, out_dim):\n",
    "\n",
    "    if out_dim <= 0:\n",
    "        raise ValueError(\"오류: out_dim이 0 이하입니다.\")\n",
    "\n",
    "    mlflow.set_tracking_uri(\"http://0.0.0.0:5000\")\n",
    "\n",
    "    model_name = \"Classification Model\"  # 등록된 모델 이름\n",
    "    model_version = 1  # 버전 번호\n",
    "\n",
    "    model_uri = f\"models:/{model_name}/{model_version}\"\n",
    "\n",
    "    base_model = mlflow.pytorch.load_model(model_uri)\n",
    "\n",
    "    base_model.head = nn.Identity()\n",
    "\n",
    "    model = MLP_layer(base_model, out_dim)\n",
    "\n",
    "    return model\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "8e7c49cbbfd24ee0a73b0cd35608eedb",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Downloading artifacts:   0%|          | 0/6 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model_name = 'vit_base_r50_s16_224.orig_in21k'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "model = create_model(model_name, pretrained, num_classes, in_chans, out_dim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layer(\n",
      "  (base_model): VisionTransformer(\n",
      "    (patch_embed): HybridEmbed(\n",
      "      (backbone): ResNetV2(\n",
      "        (stem): Sequential(\n",
      "          (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
      "          (norm): GroupNormAct(\n",
      "            32, 64, eps=1e-05, affine=True\n",
      "            (drop): Identity()\n",
      "            (act): ReLU(inplace=True)\n",
      "          )\n",
      "          (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "        )\n",
      "        (stages): Sequential(\n",
      "          (0): ResNetStage(\n",
      "            (blocks): Sequential(\n",
      "              (0): Bottleneck(\n",
      "                (downsample): DownsampleConv(\n",
      "                  (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (1): Bottleneck(\n",
      "                (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (2): Bottleneck(\n",
      "                (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 64, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (1): ResNetStage(\n",
      "            (blocks): Sequential(\n",
      "              (0): Bottleneck(\n",
      "                (downsample): DownsampleConv(\n",
      "                  (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (norm): GroupNormAct(\n",
      "                    32, 512, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 512, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (1): Bottleneck(\n",
      "                (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 512, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (2): Bottleneck(\n",
      "                (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 512, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (3): Bottleneck(\n",
      "                (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 128, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 512, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (2): ResNetStage(\n",
      "            (blocks): Sequential(\n",
      "              (0): Bottleneck(\n",
      "                (downsample): DownsampleConv(\n",
      "                  (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                  (norm): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                )\n",
      "                (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (1): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (2): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (3): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (4): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (5): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (6): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (7): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "              (8): Bottleneck(\n",
      "                (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm1): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                (norm2): GroupNormAct(\n",
      "                  32, 256, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): ReLU(inplace=True)\n",
      "                )\n",
      "                (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                (norm3): GroupNormAct(\n",
      "                  32, 1024, eps=1e-05, affine=True\n",
      "                  (drop): Identity()\n",
      "                  (act): Identity()\n",
      "                )\n",
      "                (drop_path): Identity()\n",
      "                (act3): ReLU(inplace=True)\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "        )\n",
      "        (norm): Identity()\n",
      "        (head): ClassifierHead(\n",
      "          (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n",
      "          (drop): Dropout(p=0.0, inplace=False)\n",
      "          (fc): Identity()\n",
      "          (flatten): Identity()\n",
      "        )\n",
      "      )\n",
      "      (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "    )\n",
      "    (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "    (patch_drop): Identity()\n",
      "    (norm_pre): Identity()\n",
      "    (blocks): Sequential(\n",
      "      (0): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (1): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (2): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (3): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (4): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (5): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (6): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (7): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (8): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (9): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (10): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "      (11): Block(\n",
      "        (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (attn): Attention(\n",
      "          (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "          (q_norm): Identity()\n",
      "          (k_norm): Identity()\n",
      "          (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "          (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "          (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls1): Identity()\n",
      "        (drop_path1): Identity()\n",
      "        (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "        (mlp): Mlp(\n",
      "          (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "          (act): GELU(approximate='none')\n",
      "          (drop1): Dropout(p=0.0, inplace=False)\n",
      "          (norm): Identity()\n",
      "          (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "          (drop2): Dropout(p=0.0, inplace=False)\n",
      "        )\n",
      "        (ls2): Identity()\n",
      "        (drop_path2): Identity()\n",
      "      )\n",
      "    )\n",
      "    (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "    (fc_norm): Identity()\n",
      "    (head_drop): Dropout(p=0.0, inplace=False)\n",
      "    (head): Identity()\n",
      "  )\n",
      "  (mlp_heads): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "\n",
    "class SelectAdaptivePool2d(nn.Module):\n",
    "    def __init__(self, pool_type='avg', flatten=True):\n",
    "        super(SelectAdaptivePool2d, self).__init__()\n",
    "        if pool_type == 'avg':\n",
    "            self.pool = nn.AdaptiveAvgPool2d((1, 1))  # Adaptive Average Pooling\n",
    "        elif pool_type == 'max':\n",
    "            self.pool = nn.AdaptiveMaxPool2d((1, 1))  # Adaptive Max Pooling\n",
    "        else:\n",
    "            raise ValueError(\"Unsupported pool_type: {}\".format(pool_type))\n",
    "        \n",
    "        self.flatten = flatten\n",
    "\n",
    "    def forward(self, x):\n",
    "        # x shape: (batch_size, 7, 7, 768)\n",
    "        x = x.permute(0, 3, 1, 2)  # Change to (batch_size, 768, 7, 7)\n",
    "        x = self.pool(x)  # Pooling to (batch_size, 768, 1, 1)\n",
    "        if self.flatten:\n",
    "            x = x.view(x.size(0), -1)  # Flatten to (batch_size, 768)\n",
    "        return x \n",
    "\n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "\n",
    "        self.base_model.head.global_pool = nn.Identity()\n",
    "        self.global_pool = SelectAdaptivePool2d()\n",
    "\n",
    "    def forward(self, x, m):\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        x = self.base_model(x) # x: n, k, k, d\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        patch_token = x.permute(0, 3, 1, 2) # n, d, k, k\n",
    "        \n",
    "        print(patch_token.shape)\n",
    "        \n",
    "        # drloc_loss 계산\n",
    "        #drloc_loss = dense_relative_localization_loss(patch_token, drloc_mlp, m)\n",
    "\n",
    "        \n",
    "        print(x.shape)\n",
    "        # Classifier head 적용\n",
    "        x = self.global_pool(x)\n",
    "        \n",
    "        print(x.shape)\n",
    "        \n",
    "        return x#, drloc_loss"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "model_name = 'swin_tiny_patch4_window7_224'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "base_model = BaseModel(model_name, pretrained, num_classes, in_chans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([1, 3, 224, 224])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "torch.Size([1, 768, 7, 7])\n",
      "torch.Size([1, 7, 7, 768])\n",
      "torch.Size([1, 768])\n"
     ]
    }
   ],
   "source": [
    "input_tensor = torch.randn(1, 3, 224, 224)\n",
    "\n",
    "# Set the model to evaluation mode\n",
    "base_model.eval()\n",
    "\n",
    "# Perform a forward pass\n",
    "with torch.no_grad():\n",
    "    output = base_model(input_tensor, m=64)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
