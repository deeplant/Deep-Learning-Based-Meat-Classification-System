{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 120,
   "metadata": {},
   "outputs": [],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "def conv3x3(in_dim, out_dim):\n",
    "    return torch.nn.Sequential(\n",
    "        nn.Conv2d(in_dim, out_dim, kernel_size=3, stride=2, padding=1),\n",
    "        nn.BatchNorm2d(out_dim)\n",
    "    )\n",
    "\n",
    "class Affine(nn.Module):\n",
    "    def __init__(self, dim):\n",
    "        super().__init__()\n",
    "        self.alpha = nn.Parameter(torch.ones([1, dim, 1, 1]))\n",
    "        self.beta = nn.Parameter(torch.zeros([1, dim, 1, 1]))\n",
    "\n",
    "    def forward(self, x):\n",
    "        return x * self.alpha + self.beta\n",
    "\n",
    "class SOPE(nn.Module):\n",
    "    def __init__(self, patch_size, embed_dim):\n",
    "        super().__init__()\n",
    "        self.pre_affine = Affine(3)\n",
    "        self.post_affine = Affine(embed_dim)\n",
    "\n",
    "        if patch_size[0] == 16:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim // 8),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 8, embed_dim // 4),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 4, embed_dim // 2),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 2, embed_dim),\n",
    "            )\n",
    "        elif patch_size[0] == 4:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim // 2),\n",
    "                nn.GELU(),\n",
    "                conv3x3(embed_dim // 2, embed_dim),\n",
    "            )\n",
    "        elif patch_size[0] == 2:\n",
    "            self.proj = torch.nn.Sequential(\n",
    "                conv3x3(3, embed_dim),\n",
    "                nn.GELU(),\n",
    "            )\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, C, H, W = x.shape\n",
    "        x = self.pre_affine(x)\n",
    "        x = self.proj(x)\n",
    "        x = self.post_affine(x)\n",
    "        Hp, Wp = x.shape[2], x.shape[3]\n",
    "        x = x.flatten(2).transpose(1, 2)\n",
    "        return x\n",
    "\n",
    "\n",
    "class DAFF(nn.Module):\n",
    "    def __init__(self, in_dim, hid_dim, out_dim, kernel_size=3):\n",
    "        super().__init__()\n",
    "        self.conv1 = nn.Conv2d(in_dim, hid_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.conv2 = nn.Conv2d(hid_dim, hid_dim, kernel_size=3, stride=1, padding=(kernel_size-1)//2, groups=hid_dim)\n",
    "        self.conv3 = nn.Conv2d(hid_dim, out_dim, kernel_size=1, stride=1, padding=0)\n",
    "        self.act = nn.GELU()\n",
    "        self.squeeze = nn.AdaptiveAvgPool2d((1, 1))\n",
    "        self.compress = nn.Linear(in_dim, in_dim // 4)\n",
    "        self.excitation = nn.Linear(in_dim // 4, in_dim)\n",
    "        self.bn1 = nn.BatchNorm2d(hid_dim)\n",
    "        self.bn2 = nn.BatchNorm2d(hid_dim)\n",
    "        self.bn3 = nn.BatchNorm2d(out_dim)\n",
    "\n",
    "    def forward(self, x):\n",
    "        B, N, C = x.size()\n",
    "        cls_token, tokens = torch.split(x, [1, N-1], dim=1)\n",
    "        x = tokens.reshape(B, int(math.sqrt(N-1)), int(math.sqrt(N-1)), C).permute(0, 3, 1, 2)\n",
    "        x = self.act(self.bn1(self.conv1(x)))\n",
    "        x = x + self.act(self.bn2(self.conv2(x)))\n",
    "        x = self.bn3(self.conv3(x))\n",
    "        weight = self.squeeze(x).flatten(1).reshape(B, 1, C)\n",
    "        weight = self.excitation(self.act(self.compress(weight)))\n",
    "        cls_token = cls_token * weight\n",
    "        tokens = x.flatten(2).permute(0, 2, 1)\n",
    "        out = torch.cat((cls_token, tokens), dim=1)\n",
    "        return out\n",
    "    \n",
    "class BaseModel(nn.Module):\n",
    "    def __init__(self, model_name, pretrained, num_classes, in_chans, embed_layer=SOPE):\n",
    "        super(BaseModel, self).__init__()\n",
    "        self.base_model = timm.create_model(model_name=model_name, pretrained=pretrained, num_classes=num_classes, in_chans=in_chans)\n",
    "\n",
    "#         self.base_model.patch_embed = SOPE(patch_size=(16, 16), embed_dim=768)\n",
    "        for i in range(len(self.base_model.blocks)):\n",
    "            block = self.base_model.blocks[i]\n",
    "            in_features = block.mlp.fc1.in_features\n",
    "            hidden_features = block.mlp.fc1.out_features\n",
    "            out_features = block.mlp.fc2.out_features\n",
    "\n",
    "#             # DAFF 모듈로 교체\n",
    "#             block.mlp = DAFF(in_features, hidden_features, out_features)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # 패치 임베딩\n",
    "        x = self.base_model.patch_embed(x)\n",
    "        print(f\"After patch embedding: {x.shape}\")  # (batch_size, num_patches, embed_dim)\n",
    "\n",
    "        # 클래스 토큰 추가\n",
    "        batch_size = x.shape[0]\n",
    "        print(\"before:\", self.base_model.cls_token.shape)\n",
    "        cls_token = self.base_model.cls_token.expand(batch_size, -1, -1)  # (batch_size, 1, embed_dim)\n",
    "        print(\"after:\", cls_token.shape)\n",
    "        x = torch.cat((cls_token, x), dim=1)  # (batch_size, num_patches + 1, embed_dim)\n",
    "        print(f\"After adding class token: {x.shape}\")\n",
    "        \n",
    "        # 포지셔널 임베딩 추가\n",
    "        x = x + self.base_model.pos_embed  # (batch_size, num_patches + 1, embed_dim)\n",
    "        x = self.base_model.pos_drop(x)\n",
    "        print(f\"After positional embedding: {x.shape}\")\n",
    "        \n",
    "        # 트랜스포머 블록 통과\n",
    "        x = self.base_model.blocks(x)\n",
    "        print(f\"After transformer blocks: {x.shape}\")\n",
    "        \n",
    "        # LayerNorm 적용\n",
    "        x = self.base_model.norm(x)\n",
    "        print(f\"After norm: {x.shape}\")\n",
    "        \n",
    "        # Class token 선택\n",
    "        cls_token_final = x[:, 0]\n",
    "        print(f\"After selecting class token: {cls_token_final.shape}\")\n",
    "        \n",
    "        # Classifier head 적용\n",
    "        x = self.base_model.head(cls_token_final)\n",
    "        print(f\"Final output shape: {x.shape}\")\n",
    "\n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [],
   "source": [
    "class MLP_layer(nn.Module):\n",
    "    def __init__(self, base_model, out_dim):\n",
    "        super().__init__()\n",
    "        self.base_model = base_model\n",
    "        self.out_dim = out_dim\n",
    "\n",
    "        self.num_features = self.base_model.base_model.num_features\n",
    "        \n",
    "        # out_dim 개수만큼 MLP 생성\n",
    "        self.mlp_heads = nn.ModuleList([\n",
    "            nn.Sequential(\n",
    "                nn.Linear(self.num_features, 64),\n",
    "                nn.ReLU(),\n",
    "                nn.Linear(64, 1)\n",
    "            ) for _ in range(out_dim)\n",
    "        ])\n",
    "\n",
    "    def forward(self, x):\n",
    "        base_output = self.base_model(x)\n",
    "        \n",
    "        print(\"mlp input:\", base_output.shape)\n",
    "        \n",
    "        features = base_output\n",
    "\n",
    "        outputs = [head(features) for head in self.mlp_heads]\n",
    "\n",
    "        return torch.cat(outputs, dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model_name, pretrained, num_classes, in_chans, out_dim):\n",
    "\n",
    "    if out_dim <= 0:\n",
    "        raise ValueError(\"오류: out_dim이 0 이하입니다.\")\n",
    "\n",
    "    base_model = BaseModel(model_name, pretrained, num_classes, in_chans)\n",
    "    model = MLP_layer(base_model, out_dim)\n",
    "\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "MLP_layer(\n",
      "  (base_model): BaseModel(\n",
      "    (base_model): VisionTransformer(\n",
      "      (patch_embed): HybridEmbed(\n",
      "        (backbone): ResNetV2(\n",
      "          (stem): Sequential(\n",
      "            (conv): StdConv2dSame(3, 64, kernel_size=(7, 7), stride=(2, 2), bias=False)\n",
      "            (norm): GroupNormAct(\n",
      "              32, 64, eps=1e-05, affine=True\n",
      "              (drop): Identity()\n",
      "              (act): ReLU(inplace=True)\n",
      "            )\n",
      "            (pool): MaxPool2dSame(kernel_size=(3, 3), stride=(2, 2), padding=(0, 0), dilation=(1, 1), ceil_mode=False)\n",
      "          )\n",
      "          (stages): Sequential(\n",
      "            (0): ResNetStage(\n",
      "              (blocks): Sequential(\n",
      "                (0): Bottleneck(\n",
      "                  (downsample): DownsampleConv(\n",
      "                    (conv): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                    (norm): GroupNormAct(\n",
      "                      32, 256, eps=1e-05, affine=True\n",
      "                      (drop): Identity()\n",
      "                      (act): Identity()\n",
      "                    )\n",
      "                  )\n",
      "                  (conv1): StdConv2dSame(64, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (1): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (2): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(256, 64, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 64, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(64, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (1): ResNetStage(\n",
      "              (blocks): Sequential(\n",
      "                (0): Bottleneck(\n",
      "                  (downsample): DownsampleConv(\n",
      "                    (conv): StdConv2dSame(256, 512, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                    (norm): GroupNormAct(\n",
      "                      32, 512, eps=1e-05, affine=True\n",
      "                      (drop): Identity()\n",
      "                      (act): Identity()\n",
      "                    )\n",
      "                  )\n",
      "                  (conv1): StdConv2dSame(256, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 512, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (1): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 512, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (2): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 512, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (3): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(512, 128, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 128, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(128, 512, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 512, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "            (2): ResNetStage(\n",
      "              (blocks): Sequential(\n",
      "                (0): Bottleneck(\n",
      "                  (downsample): DownsampleConv(\n",
      "                    (conv): StdConv2dSame(512, 1024, kernel_size=(1, 1), stride=(2, 2), bias=False)\n",
      "                    (norm): GroupNormAct(\n",
      "                      32, 1024, eps=1e-05, affine=True\n",
      "                      (drop): Identity()\n",
      "                      (act): Identity()\n",
      "                    )\n",
      "                  )\n",
      "                  (conv1): StdConv2dSame(512, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(2, 2), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (1): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (2): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (3): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (4): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (5): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (6): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (7): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "                (8): Bottleneck(\n",
      "                  (conv1): StdConv2dSame(1024, 256, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm1): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv2): StdConv2dSame(256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False)\n",
      "                  (norm2): GroupNormAct(\n",
      "                    32, 256, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): ReLU(inplace=True)\n",
      "                  )\n",
      "                  (conv3): StdConv2dSame(256, 1024, kernel_size=(1, 1), stride=(1, 1), bias=False)\n",
      "                  (norm3): GroupNormAct(\n",
      "                    32, 1024, eps=1e-05, affine=True\n",
      "                    (drop): Identity()\n",
      "                    (act): Identity()\n",
      "                  )\n",
      "                  (drop_path): Identity()\n",
      "                  (act3): ReLU(inplace=True)\n",
      "                )\n",
      "              )\n",
      "            )\n",
      "          )\n",
      "          (norm): Identity()\n",
      "          (head): ClassifierHead(\n",
      "            (global_pool): SelectAdaptivePool2d(pool_type=, flatten=Identity())\n",
      "            (drop): Dropout(p=0.0, inplace=False)\n",
      "            (fc): Identity()\n",
      "            (flatten): Identity()\n",
      "          )\n",
      "        )\n",
      "        (proj): Conv2d(1024, 768, kernel_size=(1, 1), stride=(1, 1))\n",
      "      )\n",
      "      (pos_drop): Dropout(p=0.0, inplace=False)\n",
      "      (patch_drop): Identity()\n",
      "      (norm_pre): Identity()\n",
      "      (blocks): Sequential(\n",
      "        (0): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (1): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (2): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (3): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (4): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (5): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (6): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (7): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (8): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (9): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (10): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "        (11): Block(\n",
      "          (norm1): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (attn): Attention(\n",
      "            (qkv): Linear(in_features=768, out_features=2304, bias=True)\n",
      "            (q_norm): Identity()\n",
      "            (k_norm): Identity()\n",
      "            (attn_drop): Dropout(p=0.0, inplace=False)\n",
      "            (proj): Linear(in_features=768, out_features=768, bias=True)\n",
      "            (proj_drop): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls1): Identity()\n",
      "          (drop_path1): Identity()\n",
      "          (norm2): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "          (mlp): Mlp(\n",
      "            (fc1): Linear(in_features=768, out_features=3072, bias=True)\n",
      "            (act): GELU(approximate='none')\n",
      "            (drop1): Dropout(p=0.0, inplace=False)\n",
      "            (norm): Identity()\n",
      "            (fc2): Linear(in_features=3072, out_features=768, bias=True)\n",
      "            (drop2): Dropout(p=0.0, inplace=False)\n",
      "          )\n",
      "          (ls2): Identity()\n",
      "          (drop_path2): Identity()\n",
      "        )\n",
      "      )\n",
      "      (norm): LayerNorm((768,), eps=1e-06, elementwise_affine=True)\n",
      "      (fc_norm): Identity()\n",
      "      (head_drop): Dropout(p=0.0, inplace=False)\n",
      "      (head): Identity()\n",
      "    )\n",
      "  )\n",
      "  (mlp_heads): ModuleList(\n",
      "    (0-4): 5 x Sequential(\n",
      "      (0): Linear(in_features=768, out_features=64, bias=True)\n",
      "      (1): ReLU()\n",
      "      (2): Linear(in_features=64, out_features=1, bias=True)\n",
      "    )\n",
      "  )\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "model_name = 'vit_base_r50_s16_224'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "model = create_model(model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 128,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "After patch embedding: torch.Size([1, 196, 768])\n",
      "before: torch.Size([1, 1, 768])\n",
      "after: torch.Size([1, 1, 768])\n",
      "After adding class token: torch.Size([1, 197, 768])\n",
      "After positional embedding: torch.Size([1, 197, 768])\n",
      "After transformer blocks: torch.Size([1, 197, 768])\n",
      "After norm: torch.Size([1, 197, 768])\n",
      "After selecting class token: torch.Size([1, 768])\n",
      "Final output shape: torch.Size([1, 768])\n",
      "mlp input: torch.Size([1, 768])\n",
      "Output shape: torch.Size([1, 5])\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "\n",
    "# 모델을 생성\n",
    "model_name = 'vit_base_r50_s16_224'\n",
    "pretrained = True\n",
    "num_classes = 0\n",
    "in_chans = 3\n",
    "out_dim = 5\n",
    "\n",
    "# 모델 생성\n",
    "model = create_model(model_name, pretrained, num_classes, in_chans, out_dim)\n",
    "\n",
    "# 랜덤 입력 생성 (배치 크기 1, 채널 수 3, 이미지 크기 224x224)\n",
    "random_input = torch.randn(1, in_chans, 224, 224)\n",
    "\n",
    "# 모델에 랜덤 입력을 넣어 출력 확인\n",
    "output = model(random_input)\n",
    "\n",
    "print(\"Output shape:\", output.shape)  # 출력의 크기 확인\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "PyTorch 2.2 (NGC 23.11/Python 3.10) on Backend.AI",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
